---
title: Настройка вашего проекта dbt с Databricks
id: set-up-your-databricks-dbt-project
description: "Узнайте больше о настройке вашего проекта dbt с Databricks."
displayText: Настройка вашего проекта dbt с Databricks
hoverSnippet: Узнайте, как настроить ваш проект dbt с Databricks.
# time_to_complete: '30 минут' закомментировано до тестирования
icon: 'databricks'
hide_table_of_contents: true
tags: ['Databricks', 'dbt Core','dbt Cloud']
level: 'Средний'
recently_updated: true
---

<div style={{maxWidth: '900px'}}>

## Введение

Databricks и dbt Labs сотрудничают, чтобы помочь командам данных мыслить как команды программной инженерии и быстрее поставлять надежные данные. Адаптер dbt-databricks позволяет пользователям dbt использовать последние функции Databricks в своем проекте dbt. Сотни клиентов уже используют dbt и Databricks для создания выразительных и надежных конвейеров данных на Lakehouse, генерируя данные, которые позволяют использовать аналитику, машинное обучение и искусственный интеллект в бизнесе.

В этом руководстве мы обсудим, как настроить ваш проект dbt на платформе Databricks Lakehouse, чтобы он масштабировался от небольшой команды до крупной организации.

## Настройка окружений Databricks

Для начала мы будем использовать Unity Catalog от Databricks. Без него мы не смогли бы разработать отдельные [окружения](https://docs.getdbt.com/docs/collaborate/environments) для разработки и производства в соответствии с нашими [рекомендациями](https://docs.getdbt.com/best-practices/how-we-structure/1-guide-overview). Это также позволяет нам убедиться, что правильные контрольные механизмы доступа были применены с использованием SQL. Вам потребуется использовать адаптер dbt-databricks для этого (в отличие от адаптера dbt-spark).

Мы создадим два разных *каталога* в Unity Catalog: **dev** и **prod**. Каталог — это контейнер верхнего уровня для *схем* (ранее известных как базы данных в Databricks), которые, в свою очередь, содержат таблицы и представления.

Наш каталог dev будет средой разработки, с которой взаимодействуют аналитические инженеры через свою IDE. Разработчики должны иметь собственный песочницу для создания и тестирования объектов без опасений перезаписать или удалить работу коллеги; мы рекомендуем создавать личные схемы для этой цели. В плане разрешений они должны иметь доступ только к каталогу **dev**.

Только производственные запуски будут иметь доступ к данным в каталоге **prod**. В будущем мы обсудим каталог **test**, в котором наша система непрерывной интеграции/непрерывного развертывания (CI/CD) сможет выполнять `dbt test`.

Пока давайте упростим задачу и [создадим два каталога](https://docs.databricks.com/sql/language-manual/sql-ref-syntax-ddl-create-catalog.html), используя Data Explorer или в SQL редакторе с помощью следующих команд:

```sql
create catalog if not exists dev;
create catalog if not exists prod;
```

Пока ваш разработчик имеет права на запись в каталог данных dev, нет необходимости заранее создавать схемы песочницы.

## Настройка сервисных принципалов

Когда аналитический инженер запускает проект dbt из своей IDE, вполне нормально, что результирующие запросы выполняются с идентичностью этого пользователя. Однако мы хотим, чтобы производственные запуски выполнялись с идентичностью *сервисного принципала*. Напоминаем, что сервисный принципал — это безголосый аккаунт, который не принадлежит реальному человеку.

Сервисные принципалы используются для исключения людей из развертывания в производственной среде для удобства и безопасности. Личные идентичности не должны использоваться для создания производственных конвейеров, так как они могут сломаться, если пользователь покинет компанию или изменит свои учетные данные. Также не должно быть произвольных команд, изменяющих производственные данные. Только запланированные задания и выполняемый код, который прошел тесты CI и код-ревью, должны иметь возможность изменять производственные данные. Если что-то сломается, будет доступен проверяемый след изменений, чтобы найти коренную причину, легко вернуться к последней рабочей версии кода и минимизировать влияние на конечных пользователей.

[Давайте создадим сервисный принципал](https://docs.databricks.com/administration-guide/users-groups/service-principals.html#add-a-service-principal-to-your-databricks-account) в Databricks:

1. Попросите администратора вашей учетной записи Databricks [добавить сервисный принципал](https://docs.databricks.com/administration-guide/users-groups/service-principals.html#add-a-service-principal-to-your-databricks-account) в вашу учетную запись. Имя сервисного принципала должно отличаться от идентификатора пользователя и четко указывать его назначение (например, dbt_prod_sp).
2. Добавьте сервисный принципал в любые группы, членом которых он должен быть на данный момент. Более подробную информацию о разрешениях можно найти в нашем ["руководстве по лучшим практикам Unity Catalog"](/best-practices/dbt-unity-catalog-best-practices).
3. [Добавьте сервисный принципал в ваше рабочее пространство](https://docs.databricks.com/administration-guide/users-groups/service-principals.html#add-a-service-principal-to-a-workspace) и примените любые [необходимые права доступа](https://docs.databricks.com/administration-guide/users-groups/service-principals.html#add-a-service-principal-to-a-workspace-using-the-admin-console), такие как доступ к Databricks SQL и доступ к рабочему пространству.

## Настройка вычислений Databricks

Когда вы запускаете проект dbt, он генерирует SQL, который может выполняться на All Purpose Clusters или SQL warehouses. Мы настоятельно рекомендуем запускать сгенерированный dbt SQL на SQL warehouse Databricks. Поскольку SQL warehouses оптимизированы для выполнения SQL-запросов, вы можете сэкономить на затратах с меньшим временем работы кластера для выполнения запросов. Если вам нужно отладить, у вас также будет доступ к профилю запроса. Мы рекомендуем использовать кластер без сервера, если вы хотите минимизировать время, затрачиваемое на развертывание кластера, и избежать необходимости изменять размеры кластера в зависимости от рабочих процессов.

Давайте [создадим SQL warehouse Databricks](https://docs.databricks.com/sql/admin/sql-endpoints.html#create-a-sql-warehouse):

1. Нажмите **SQL Warehouses** в боковом меню.
2. Нажмите *Создать SQL Warehouse*.
3. Введите имя для warehouse.
4. Примите настройки по умолчанию или измените их.
5. Нажмите *Создать*.
6. Настройте разрешения warehouse, чтобы убедиться, что наш сервисный принципал и разработчик имеют правильный доступ.

Мы не рассматриваем Python в этом посте, но если вы хотите узнать больше, ознакомьтесь с этими [документами](https://docs.getdbt.com/docs/build/python-models#specific-data-platforms). В зависимости от вашей нагрузки вы можете создать более крупный SQL Warehouse для производственных рабочих процессов, имея при этом меньший SQL Warehouse для разработки (если вы не используете Serverless SQL Warehouses). По мере роста вашего проекта вы можете применить [конфигурации вычислений для моделей](/reference/resource-configs/databricks-configs#specifying-the-compute-for-models).

## Настройка вашего проекта dbt

Теперь, когда компоненты Databricks на месте, мы можем настроить наш проект dbt. Это включает в себя подключение dbt к нашему SQL warehouse Databricks для выполнения SQL-запросов и использование системы контроля версий, такой как GitHub, для хранения нашего кода трансформации.

Если вы мигрируете существующий проект dbt с адаптера dbt-spark на dbt-databricks, следуйте этому [руководству по миграции](/guides/migrate-from-spark-to-databricks), чтобы переключить адаптеры без необходимости обновлять учетные данные разработчика и другие существующие конфигурации.

Если вы начинаете новый проект dbt, следуйте приведенным ниже шагам. Для более подробного процесса настройки ознакомьтесь с нашим [руководством по быстрому старту](/guides/databricks).

### Подключение dbt к Databricks

Сначала вам нужно подключить ваш проект dbt к Databricks, чтобы он мог отправлять инструкции по трансформации и создавать объекты в Unity Catalog. Следуйте инструкциям для [dbt Cloud](/guides/databricks?step=4) или [Core](https://docs.getdbt.com/reference/warehouse-setups/databricks-setup), чтобы настроить учетные данные подключения вашего проекта.

Каждый разработчик должен сгенерировать свой Databricks PAT и использовать токен в своих учетных данных для разработки. Они также укажут уникальную схему разработчика, которая будет хранить таблицы и представления, созданные запусками dbt, выполненными из их IDE. Это обеспечивает изолированные среды для разработчиков и гарантирует, что доступ к данным соответствует назначению.

Давайте сгенерируем [личный токен доступа Databricks (PAT)](https://docs.databricks.com/sql/user/security/personal-access-tokens.html) для разработки:

1. В Databricks нажмите на ваше имя пользователя в верхней панели и выберите Настройки пользователя в выпадающем меню.
2. На вкладке Токен доступа нажмите Создать новый токен.
3. Нажмите Создать.
4. Скопируйте отображаемый токен и нажмите Готово. (не потеряйте его!)

Для ваших учетных данных разработки/profiles.yml:

1. Установите ваш каталог по умолчанию на dev.
2. Ваша схема разработчика должна быть названа в честь вас. Мы рекомендуем dbt_&lt;первая_буква_имени&gt;&lt;фамилия&gt;.

Во время вашего первого вызова `dbt run` dbt создаст схему разработчика, если она еще не существует в каталоге dev.

## Определение вашего окружения развертывания dbt

Нам нужно дать dbt способ развертывать код вне сред разработки. Для этого мы будем использовать [окружения dbt](https://docs.getdbt.com/docs/collaborate/environments), чтобы определить производственные цели, с которыми будут взаимодействовать конечные пользователи.

Проекты Core могут использовать [цели в профилях](https://docs.getdbt.com/docs/core/connection-profiles#understanding-targets-in-profiles) для разделения окружений. [Окружения dbt Cloud](https://docs.getdbt.com/docs/cloud/develop-in-the-cloud#set-up-and-access-the-cloud-ide) позволяют вам определять окружения через интерфейс и [планировать задания](/guides/databricks#create-and-run-a-job) для конкретных окружений.

Давайте настроим наше окружение развертывания:

1. Следуйте инструкциям Databricks, чтобы [настроить токен вашего сервисного принципала](https://docs.databricks.com/dev-tools/service-principals.html#use-curl-or-postman). Обратите внимание, что `lifetime_seconds` определит, как долго этот токен будет действителен. Вы должны использовать большое число здесь, чтобы избежать частого обновления токенов и сбоев производственных заданий.
2. Теперь давайте вернемся в dbt Cloud, чтобы заполнить поля окружения. Нажмите на окружения в интерфейсе dbt Cloud или определите новую цель в вашем profiles.yml.
3. Установите *каталог* производственной среды на **prod** каталог, созданный выше. Укажите [токен сервиса](https://docs.databricks.com/administration-guide/users-groups/service-principals.html#manage-access-tokens-for-a-service-principal) для вашего **prod** сервисного принципала и установите его в качестве *токена* в учетных данных развертывания вашей производственной среды.
4. Установите схему по умолчанию для вашей производственной среды. Это можно переопределить с помощью [пользовательских схем](https://docs.getdbt.com/docs/build/custom-schemas#what-is-a-custom-schema), если вам нужно использовать более одной.
5. Укажите токен вашего сервисного принципала.

## Подключение dbt к вашему репозиторию git

Далее вам нужно место для хранения и контроля версий вашего кода, которое позволит вам сотрудничать с коллегами. Подключите ваш проект dbt к репозиторию git с помощью [dbt Cloud](/guides/databricks#set-up-a-dbt-cloud-managed-repository). Проекты [Core](/guides/manual-install#create-a-repository) будут использовать git CLI.

### Следующие шаги

Теперь, когда ваш проект настроен, вы можете начать трансформировать ваши данные Databricks с помощью dbt. Чтобы помочь вам эффективно масштабироваться, мы рекомендуем следовать нашим лучшим практикам, начиная с [лучших практик Unity Catalog](/best-practices/dbt-unity-catalog-best-practices), затем вы можете [оптимизировать модели dbt на Databricks](/guides/optimize-dbt-models-on-databricks).

</div>