---
title: Настройка CI/CD с помощью пользовательских пайплайнов
id: custom-cicd-pipelines
description: "Узнайте о преимуществах кода аналитики под контролем версий и пользовательских пайплайнов в dbt для улучшенного тестирования кода и автоматизации рабочих процессов в процессе разработки."
displayText: Узнайте о коде под контролем версий, пользовательских пайплайнах и улучшенном тестировании кода.
hoverSnippet: Узнайте о коде под контролем версий, пользовательских пайплайнах и улучшенном тестировании кода.
# time_to_complete: '30 минут' закомментировано до тестирования
icon: 'guides'
hide_table_of_contents: true
tags: ['dbt Cloud', 'Orchestration', 'CI']
level: 'Средний'
recently_updated: true
search_weight: "heavy"
keywords:
  - bitbucket pipeline, пользовательские пайплайны, github, gitlab, azure devops, ci/cd пользовательский пайплайн
---
<div style={{maxWidth: '900px'}}>

## Введение

Одним из основных принципов dbt является то, что аналитический код должен находиться под контролем версий. Это приносит вашей организации множество преимуществ в плане сотрудничества, согласованности кода, стабильности и возможности отката к предыдущей версии. Существует дополнительное преимущество, которое предоставляет ваша платформа хостинга кода, и которое часто упускается из виду или используется недостаточно. Некоторые из вас могут иметь опыт использования функции [вебхуков dbt Cloud](https://docs.getdbt.com/docs/dbt-cloud/using-dbt-cloud/cloud-enabling-continuous-integration) для запуска задания при создании PR. Это фантастическая возможность, которая удовлетворяет большинство случаев использования для тестирования вашего кода перед слиянием с производственной версией. Однако бывают обстоятельства, когда организации требуется дополнительная функциональность, такая как выполнение рабочих процессов при каждом коммите (линтинг) или выполнение рабочих процессов после завершения слияния. В этой статье мы покажем вам, как настроить пользовательские пайплайны для линтинга вашего проекта и запуска задания dbt Cloud через API.

Обратите внимание на терминологию в этой статье, так как каждая платформа хостинга кода использует разные термины для схожих понятий. Термины `pull request` (PR) и `merge request` (MR) используются взаимозаменяемо для обозначения процесса слияния одной ветки в другую.

### Что такое пайплайны?

Пайплайны (которые известны под множеством названий, таких как рабочие процессы, действия или шаги сборки) представляют собой серию предопределенных заданий, которые запускаются при определенных событиях в вашем репозитории (создание PR, отправка коммита, слияние ветки и т.д.). Эти задания могут выполнять практически все, что вы хотите, при условии, что у вас есть соответствующий доступ и навыки программирования.

Задания выполняются на [runner'ах](https://docs.github.com/en/actions/learn-github-actions/understanding-github-actions#runners), которые являются виртуальными серверами. Runner'ы поставляются с предустановленной операционной системой Ubuntu Linux, macOS или Windows. Это означает, что команды, которые вы выполняете, определяются операционной системой вашего runner'а. Вы увидите, как это будет иметь значение позже в настройке, но пока просто помните, что ваш код выполняется на виртуальных серверах, которые, как правило, хостятся платформой хостинга кода.

![Схема работы пайплайнов](/img/guides/orchestration/custom-cicd-pipelines/pipeline-diagram.png)

Обратите внимание, что runner'ы, хостящиеся на вашей платформе хостинга кода, предоставляют определенное количество бесплатного времени. После этого могут применяться сборы в зависимости от того, как настроен ваш аккаунт. У вас также есть возможность хостить свои собственные runner'ы. Это выходит за рамки данной статьи, но ознакомьтесь с приведенными ниже ссылками для получения дополнительной информации, если вы заинтересованы в настройке:

- Информация о выставлении счетов для runner'ов, размещенных в репозитории:
  - [GitHub](https://docs.github.com/en/billing/managing-billing-for-github-actions/about-billing-for-github-actions)
  - [GitLab](https://docs.gitlab.com/ee/ci/pipelines/cicd_minutes.html)
  - [Bitbucket](https://bitbucket.org/product/features/pipelines#)
- Информация о самохостинге runner'ов:
  - [GitHub](https://docs.github.com/en/actions/hosting-your-own-runners/about-self-hosted-runners)
  - [GitLab](https://docs.gitlab.com/runner/)
  - [Bitbucket](https://support.atlassian.com/bitbucket-cloud/docs/runners/)

Кроме того, если вы используете бесплатный тариф GitLab, вы все равно можете следовать этому руководству, но вам может потребоваться предоставить кредитную карту для подтверждения вашего аккаунта. Вы увидите что-то подобное в первый раз, когда попытаетесь запустить пайплайн:

![Предупреждение от GitLab о необходимости предоставить платежную информацию](/img/guides/orchestration/custom-cicd-pipelines/gitlab-cicd-payment-warning.png)

### Как настроить пайплайны

Это руководство предоставляет детали для нескольких платформ хостинга кода. Где шаги уникальны, они представлены без выбора. Если код специфичен для платформы (т.е. GitHub, GitLab, Bitbucket), вы увидите вариант выбора для каждой.

Пайплайны могут быть запущены различными событиями. Процесс [вебхука dbt Cloud](https://docs.getdbt.com/docs/dbt-cloud/using-dbt-cloud/cloud-enabling-continuous-integration) уже запускает выполнение, если вы хотите запустить свои задания при запросе на слияние, поэтому это руководство сосредоточено на запуске пайплайнов для каждого пуша и когда PR сливаются. Поскольку пуши происходят часто в проекте, мы сделаем это задание очень простым и быстрым, используя линтинг с SQLFluff. Пайплайн, который запускается при запросах на слияние, будет запускаться реже и может использоваться для вызова API dbt Cloud для запуска конкретного задания. Это может быть полезно, если у вас есть специфические требования, которые необходимо выполнить, когда код обновляется в производственной среде, например, выполнение `--full-refresh` для всех затронутых инкрементальных моделей.

Вот краткий обзор того, что этот пайплайн будет выполнять:

![Схема, показывающая создаваемые пайплайны и вовлеченные программы](/img/guides/orchestration/custom-cicd-pipelines/pipeline-programs-diagram.png)

## Запуск задания dbt Cloud при слиянии

Это задание потребует немного больше времени на настройку, но является хорошим примером того, как вызвать API dbt Cloud из пайплайна CI/CD. Представленные здесь концепции могут быть обобщены и использованы любым способом, который лучше всего подходит для вашего случая использования.

:::tip Запуск при слиянии

Если ваш поставщик Git имеет встроенную интеграцию с dbt Cloud, вы можете воспользоваться возможностью настройки [Merge jobs](/docs/deploy/merge-jobs) в интерфейсе.

:::

Настройка ниже показывает, как вызвать API dbt Cloud для запуска задания каждый раз, когда происходит пуш в вашу основную ветку (ветка, в которую обычно сливаются запросы на слияние. Обычно называется основной, первичной или мастер-веткой, но может называться иначе).

### 1. Получите свой API-ключ dbt Cloud

При запуске пайплайна CI/CD вы захотите использовать токен сервиса вместо любого индивидуального API-ключа. Существуют [подробные документы](https://docs.getdbt.com/docs/dbt-cloud-apis/service-tokens) по этому вопросу, но ниже приведен краткий обзор (это должно выполняться администратором аккаунта):

- Войдите в свой аккаунт dbt Cloud
- В верхнем левом углу нажмите кнопку меню, затем *Настройки аккаунта*
- Нажмите *Токены сервиса* слева
- Нажмите *Новый токен*, чтобы создать новый токен специально для вызовов API CI/CD
- Назовите свой токен, например, “CICD Token”
- Нажмите кнопку *+Добавить* под *Доступом* и предоставьте этому токену разрешение *Job Admin*
- Нажмите *Сохранить*, и вы увидите серый блок с вашим токеном. Скопируйте его и сохраните в безопасном месте (это пароль, и с ним следует обращаться соответственно).

<Lightbox src="/img/guides/orchestration/custom-cicd-pipelines/dbt-service-token-page.png" title="Просмотр страницы dbt Cloud, где создаются токены сервиса" width="85%" />

Вот видео, показывающее шаги:

<WistiaVideo id="iub17te9ir" />

### 2. Поместите свой API-ключ dbt Cloud в свой репозиторий

Эта следующая часть будет происходить на вашей платформе хостинга кода. Нам нужно сохранить ваш API-ключ из предыдущего шага в секретах репозитория, чтобы задание, которое мы создаем, могло к нему получить доступ. **Не рекомендуется** когда-либо сохранять пароли или API-ключи в вашем коде, поэтому этот шаг гарантирует, что ваш ключ останется в безопасности, но все еще будет доступен для ваших пайплайнов.

<Tabs
  defaultValue="github"
  values={[
    { label: 'GitHub', value: 'github', },
    {label: 'GitLab', value: 'gitlab', },
    {label: 'Azure DevOps', value: 'ado', },  
    {label: 'Bitbucket', value: 'bitbucket', },
  ]
}>
<TabItem value="github">

- Откройте свой репозиторий, в котором вы хотите запустить пайплайн (тот же, который содержит ваш проект dbt)
- Нажмите *Настройки*, чтобы открыть параметры репозитория
- Слева нажмите выпадающее меню *Секреты и переменные* в разделе *Безопасность*
- Из этого списка нажмите *Actions*
- Ближе к середине экрана нажмите кнопку *Новый секрет репозитория*
- Вам будет предложено ввести имя, давайте назовем его `DBT_API_KEY`
  - **Очень важно, чтобы вы скопировали/вставили это имя точно, так как оно используется в скриптах ниже.**
- В разделе *Секрет* вставьте ключ, который вы скопировали из dbt Cloud
- Нажмите *Добавить секрет*, и вы готовы!

** Быстрая заметка о безопасности: хотя использование секрета репозитория является самым простым способом настройки этого секрета, у вас есть и другие варианты в GitHub. Они выходят за рамки этого руководства, но могут быть полезны, если вам нужно создать более безопасную среду для выполнения действий. Ознакомьтесь с документацией GitHub по секретам [здесь](https://docs.github.com/en/actions/security-guides/encrypted-secrets).*

Вот видео, показывающее эти шаги:

<WistiaVideo id="u7mo30puql" />

</TabItem>

<TabItem value="gitlab">

- Откройте свой репозиторий, в котором вы хотите запустить пайплайн (тот же, который содержит ваш проект dbt)
- Нажмите *Настройки* > *CI/CD*
- В разделе *Переменные* нажмите *Развернуть*, затем нажмите *Добавить переменную*
- Вам будет предложено ввести имя, давайте назовем его `DBT_API_KEY`
  - **Очень важно, чтобы вы скопировали/вставили это имя точно, так как оно используется в скриптах ниже.**
- В разделе *Значение* вставьте ключ, который вы скопировали из dbt Cloud
- Убедитесь, что флажок рядом с *Защитить переменную* не установлен, а флажок рядом с *Скрыть переменную* установлен (см. ниже)
  - “Защищенная” означает, что переменная доступна только в пайплайнах, которые выполняются на защищенных ветках или защищенных тегах - это не сработает для нас, потому что мы хотим запускать этот пайплайн на нескольких ветках. “Скрытая” означает, что она будет доступна вашему runner'у пайплайна, но будет скрыта в логах.

  <Lightbox src="/img/guides/orchestration/custom-cicd-pipelines/dbt-api-key-gitlab.png" title="[Просмотр окна GitLab для ввода DBT_API_KEY" width="80%" />

    Вот видео, показывающее эти шаги:
    <WistiaVideo id="rgqs14f816" />


</TabItem>
<TabItem value="ado">

В Azure:

- Откройте свой проект Azure DevOps, в котором вы хотите запустить пайплайн (тот же, который содержит ваш проект dbt)
- Нажмите на *Пайплайны*, а затем *Создать пайплайн*
- Выберите, где находится ваш git-код. Это должно быть *Azure Repos Git*
  - Выберите свой git-репозиторий из списка
- Выберите *Стартовый пайплайн* (это будет обновлено позже на Шаге 4)
- Нажмите на *Переменные*, а затем *Новая переменная*
- В поле *Имя* введите `DBT_API_KEY`
  - **Очень важно, чтобы вы скопировали/вставили это имя точно, так как оно используется в скриптах ниже.**
- В разделе *Значение* вставьте ключ, который вы скопировали из dbt Cloud
- Убедитесь, что флажок рядом с *Сохранить это значение в секрете* установлен. Это скроет значение в логах, и вы не сможете увидеть значение переменной в интерфейсе.
- Нажмите *ОК*, а затем *Сохранить*, чтобы сохранить переменную
- Сохраните свой новый пайплайн Azure

<Lightbox src="/img/guides/orchestration/custom-cicd-pipelines/dbt-api-key-azure.png" title="Просмотр окна пайплайнов Azure для ввода DBT_API_KEY"/>

</TabItem>
<TabItem value="bitbucket">

В Bitbucket:

- Откройте свой репозиторий, в котором вы хотите запустить пайплайн (тот же, который содержит ваш проект dbt)
- В левом меню нажмите *Настройки репозитория*
- Прокрутите вниз до конца левого меню и выберите *Переменные репозитория*
- В поле *Имя* введите `DBT_API_KEY`
  - **Очень важно, чтобы вы скопировали/вставили это имя точно, так как оно используется в скриптах ниже.**
- В разделе *Значение* вставьте ключ, который вы скопировали из dbt Cloud
- Убедитесь, что флажок рядом с *Защищено* установлен. Это скроет значение в логах, и вы не сможете увидеть значение переменной в интерфейсе.
- Нажмите *Добавить*, чтобы сохранить переменную

    ![Просмотр окна Bitbucket для ввода DBT_API_KEY](/img/guides/orchestration/custom-cicd-pipelines/dbt-api-key-bitbucket.png)

    Вот видео, показывающее эти шаги:
    <WistiaVideo id="1fddpsqpfv" />

  

</TabItem>
</Tabs>

### 3. Создайте скрипт для запуска задания dbt Cloud через вызов API

В вашем проекте dbt Cloud создайте новую папку на корневом уровне с именем `python`. В этой папке создайте файл с именем `run_and_monitor_dbt_job.py`. Вы скопируете содержимое из этого [gist](https://gist.github.com/b-per/f4942acb8584638e3be363cb87769b48) в этот файл.

```yaml
my_awesome_project
├── python
│   └── run_and_monitor_dbt_job.py
```

Этот файл Python содержит все, что вам нужно для вызова API dbt Cloud, но требует нескольких входных данных (см. сниппет ниже). Эти входные данные передаются в этот скрипт через переменные окружения, которые будут определены на следующем шаге.

```python
#------------------------------------------------------------------------------
# получение переменных окружения
#------------------------------------------------------------------------------
api_base        = os.getenv('DBT_URL', 'https://cloud.getdbt.com/') # по умолчанию многоарендный URL
job_cause       = os.getenv('DBT_JOB_CAUSE', 'API-triggered job') # по умолчанию общее сообщение
git_branch      = os.getenv('DBT_JOB_BRANCH', None) # по умолчанию None
schema_override = os.getenv('DBT_JOB_SCHEMA_OVERRIDE', None) # по умолчанию None
api_key         = os.environ['DBT_API_KEY']  # без значения по умолчанию, просто выдаст ошибку, если ключ не предоставлен
account_id      = os.environ['DBT_ACCOUNT_ID'] # без значения по умолчанию, просто выдаст ошибку, если id не предоставлен
project_id      = os.environ['DBT_PROJECT_ID'] # без значения по умолчанию, просто выдаст ошибку, если id не предоставлен
job_id          = os.environ['DBT_PR_JOB_ID'] # без значения по умолчанию, просто выдаст ошибку, если id не предоставлен
```

**Обязательные входные данные:**

Чтобы вызвать API dbt Cloud, скрипту нужно несколько данных. Самый простой способ получить эти значения - открыть задание, которое вы хотите запустить в dbt Cloud. URL, когда вы находитесь внутри задания, содержит все необходимые вам значения:

- `DBT_ACCOUNT_ID` - это число сразу после `accounts/` в URL
- `DBT_PROJECT_ID` - это число сразу после `projects/` в URL
- `DBT_PR_JOB_ID` - это число сразу после `jobs/` в URL

![Изображение URL задания dbt Cloud с выделенными частями для аккаунта, проекта и задания](/img/guides/orchestration/custom-cicd-pipelines/dbt-cloud-job-url.png)

### 4. Обновите свой проект, чтобы включить новый вызов API

<Tabs
  defaultValue="github"
  values={[
    { label: 'GitHub', value: 'github', },
    {label: 'GitLab', value: 'gitlab', },
    {label: 'Azure DevOps', value: 'ado', },
    {label: 'Bitbucket', value: 'bitbucket', },
  ]
}>
<TabItem value="github">

Для этого нового задания мы добавим файл для вызова API dbt Cloud с именем `dbt_run_on_merge.yml`.

```yaml
my_awesome_project
├── python
│   └── run_and_monitor_dbt_job.py
├── .github
│   ├── workflows
│   │   └── dbt_run_on_merge.yml
│   │   └── lint_on_push.yml
```

YAML-файл будет выглядеть довольно похоже на наше предыдущее задание, но есть новый раздел под названием `env`, который мы будем использовать для передачи необходимых переменных. Обновите переменные ниже, чтобы они соответствовали вашей настройке на основе комментариев в файле.

Стоит отметить, что мы изменили раздел `on:`, чтобы теперь он выполнялся **только** при пушах в ветку с именем `main` (т.е. когда PR сливается). Ознакомьтесь с [документацией GitHub](https://docs.github.com/en/actions/using-workflows/events-that-trigger-workflows) по этим фильтрам для получения дополнительных случаев использования.

```yaml
name: запуск задания dbt Cloud при пуше

# Этот фильтр говорит, что это задание должно выполняться только при пуше в основную ветку
# Это работает на предположении, что вы ограничили эту ветку только для всех PR, чтобы пушить в основную ветку
# Обновите имя, чтобы оно соответствовало имени вашей основной ветки
on:
  push:
    branches:
      - 'main'

jobs:

  # задание вызывает API dbt Cloud для запуска задания
  run_dbt_cloud_job:
    name: Запуск задания dbt Cloud
    runs-on: ubuntu-latest

  # Установите переменные окружения, необходимые для выполнения
    env:
      DBT_ACCOUNT_ID: 00000 # введите свой идентификатор аккаунта
      DBT_PROJECT_ID: 00000 # введите свой идентификатор проекта
      DBT_PR_JOB_ID:  00000 # введите свой идентификатор задания
      DBT_API_KEY: ${{ secrets.DBT_API_KEY }}
      DBT_JOB_CAUSE: 'GitHub Pipeline CI Job' 
      DBT_JOB_BRANCH: ${{ github.ref_name }}

    steps:
      - uses: "actions/checkout@v4"
      - uses: "actions/setup-python@v5"
        with:
          python-version: "3.9"
      - name: Запуск задания dbt Cloud
        run: "python python/run_and_monitor_dbt_job.py"
```

</TabItem>
<TabItem value="gitlab">

Для этого задания мы настроим его с помощью файла `gitlab-ci.yml`, как в предыдущем шаге (см. Шаг 1 настройки линтинга для получения дополнительной информации). YAML-файл будет выглядеть довольно похоже на наше предыдущее задание, но есть новый раздел под названием `variables`, который мы будем использовать для передачи необходимых переменных в Python-скрипт. Обновите этот раздел, чтобы он соответствовал вашей настройке на основе комментариев в файле.

Обратите внимание, что раздел `rules:` теперь говорит, чтобы выполнять **только** при пушах в ветку с именем `main`, например, когда PR сливается. Ознакомьтесь с [документацией GitLab](https://docs.gitlab.com/ee/ci/yaml/#rules) по этим фильтрам для получения дополнительных случаев использования.

<Tabs
  defaultValue="single-job"
  values={[
    { label: 'Только задание dbt Cloud', value: 'single-job', },
    {label: 'Линтинг и задание dbt Cloud', value: 'multi-job', },
  ]
}>
<TabItem value="single-job">

```yaml
image: python:3.9

variables:
  DBT_ACCOUNT_ID: 00000 # введите свой идентификатор аккаунта
  DBT_PROJECT_ID: 00000 # введите свой идентификатор проекта
  DBT_PR_JOB_ID:  00000 # введите свой идентификатор задания
  DBT_API_KEY: $DBT_API_KEY # секретная переменная в аккаунте gitlab
  DBT_URL: https://cloud.getdbt.com 
  DBT_JOB_CAUSE: 'GitLab Pipeline CI Job' 
  DBT_JOB_BRANCH: $CI_COMMIT_BRANCH

stages:
  - build

# это задание вызывает API dbt Cloud для запуска задания
run-dbt-cloud-job:
  stage: build
  rules:
    - if: $CI_PIPELINE_SOURCE == "push" && $CI_COMMIT_BRANCH == 'main'
  script:
    - python python/run_and_monitor_dbt_job.py
```

</TabItem>
<TabItem value="multi-job">

```yaml
image: python:3.9

variables:
  DBT_ACCOUNT_ID: 00000 # введите свой идентификатор аккаунта
  DBT_PROJECT_ID: 00000 # введите свой идентификатор проекта
  DBT_PR_JOB_ID:  00000 # введите свой идентификатор задания
  DBT_API_KEY: $DBT_API_KEY # секретная переменная в аккаунте gitlab
  DBT_URL: https://cloud.getdbt.com 
  DBT_JOB_CAUSE: 'GitLab Pipeline CI Job' 
  DBT_JOB_BRANCH: $CI_COMMIT_BRANCH

stages:
  - pre-build
  - build

# это задание запускает SQLFluff с определенным набором правил
# обратите внимание, что диалект установлен на Snowflake, поэтому настройте его в соответствии с вашей конфигурацией
# детали о правилах линтера: https://docs.sqlfluff.com/en/stable/rules.html
lint-project:
  stage: pre-build
  rules:
    - if: $CI_PIPELINE_SOURCE == "push" && $CI_COMMIT_BRANCH != 'main'
  script:
    - python -m pip install sqlfluff==0.13.1
    - sqlfluff lint models --dialect snowflake --rules L019,L020,L021,L022

# это задание вызывает API dbt Cloud для запуска задания
run-dbt-cloud-job:
  stage: build
  rules:
    - if: $CI_PIPELINE_SOURCE == "push" && $CI_COMMIT_BRANCH == 'main'
  script:
    - python python/run_and_monitor_dbt_job.py
```

</TabItem>
</Tabs>

</TabItem>
<TabItem value="ado">

Для этого нового задания откройте существующий пайплайн Azure, который вы создали выше, и выберите кнопку *Редактировать*. Мы хотим отредактировать соответствующий YAML-файл пайплайна Azure с соответствующей конфигурацией, вместо стартового кода, а также включить раздел `variables`, чтобы передать необходимые переменные.

Скопируйте приведенный ниже YAML-файл в свой пайплайн Azure и обновите переменные ниже, чтобы они соответствовали вашей настройке на основе комментариев в файле. Стоит отметить, что мы изменили раздел `trigger`, чтобы он выполнялся **только** при пушах в ветку с именем `main` (например, когда PR сливается в вашу основную ветку).

Ознакомьтесь с [документацией Azure](https://learn.microsoft.com/en-us/azure/devops/pipelines/build/triggers?view=azure-devops) по этим фильтрам для получения дополнительных случаев использования.

```yaml
name: Запуск задания dbt Cloud

trigger: [ main ] # выполняется при пушах в основную ветку

variables:
  DBT_URL:                 https://cloud.getdbt.com # без завершающего обратного слэша, настройте это соответственно для развертываний с одним арендатором
  DBT_JOB_CAUSE:           'Azure Pipeline CI Job' # предоставьте описательное сообщение о причине задания для упрощения отладки в будущем
  DBT_ACCOUNT_ID:          00000 # введите свой идентификатор аккаунта
  DBT_PROJECT_ID:          00000 # введите свой идентификатор проекта
  DBT_PR_JOB_ID:           00000 # введите свой идентификатор задания

steps:
  - task: UsePythonVersion@0
    inputs:
      versionSpec: '3.7'
    displayName: 'Использовать Python 3.7'

  - script: |
      python -m pip install requests
    displayName: 'Установить зависимости python'

  - script: |
      python -u ./python/run_and_monitor_dbt_job.py
    displayName: 'Запустить задание dbt '
    env:
      DBT_API_KEY: $(DBT_API_KEY) # Установите эти значения как секреты в веб-интерфейсе пайплайнов Azure
```

</TabItem>
<TabItem value="bitbucket">

Для этого задания мы настроим его с помощью файла `bitbucket-pipelines.yml`, как в предыдущем шаге (см. Шаг 1 настройки линтинга для получения дополнительной информации). YAML-файл будет выглядеть довольно похоже на наше предыдущее задание, но мы будем передавать необходимые переменные в Python-скрипт с помощью операторов `export`. Обновите этот раздел, чтобы он соответствовал вашей настройке на основе комментариев в файле.

<Tabs
  defaultValue="single-job"
  values={[
    { label: 'Только задание dbt Cloud', value: 'single-job', },
    {label: 'Линтинг и задание dbt Cloud', value: 'multi-job', },
  ]
}>
<TabItem value="single-job">

```yaml
image: python:3.11.1


pipelines:
  branches:
    'main': # переопределите, если ваша основная ветка не называется "main"
      - step:
          name: 'Запуск задания dbt Cloud'
          script:
            - export DBT_URL="https://cloud.getdbt.com" # если у вас развертывание с одним арендатором, настройте это соответственно
            - export DBT_JOB_CAUSE="Bitbucket Pipeline CI Job"
            - export DBT_ACCOUNT_ID=00000 # введите свой идентификатор аккаунта здесь
            - export DBT_PROJECT_ID=00000 # введите свой идентификатор проекта здесь
            - export DBT_PR_JOB_ID=00000 # введите свой идентификатор задания здесь
            - python python/run_and_monitor_dbt_job.py
```

</TabItem>
<TabItem value="multi-job">

```yaml
image: python:3.11.1


pipelines:
  branches:
    '**': # это устанавливает подстановочный знак для запуска на каждой ветке, если не указано иное ниже
      - step:
          name: Линтинг проекта dbt
          script:
            - python -m pip install sqlfluff==0.13.1
            - sqlfluff lint models --dialect snowflake --rules L019,L020,L021,L022

    'main': # переопределите, если ваша основная ветка не называется "main"
      - step:
          name: 'Запуск задания dbt Cloud'
          script:
            - export DBT_URL="https://cloud.getdbt.com" # если у вас развертывание с одним арендатором, настройте это соответственно
            - export DBT_JOB_CAUSE="Bitbucket Pipeline CI Job"
            - export DBT_ACCOUNT_ID=00000 # введите свой идентификатор аккаунта здесь
            - export DBT_PROJECT_ID=00000 # введите свой идентификатор проекта здесь
            - export DBT_PR_JOB_ID=00000 # введите свой идентификатор задания здесь
            - python python/run_and_monitor_dbt_job.py
```

</TabItem>
</Tabs>

</TabItem>
</Tabs>

### 5. Протестируйте ваше новое действие

Теперь, когда у вас есть новое действие, пришло время протестировать его! Поскольку это изменение настроено на выполнение только при слиянии в вашу основную ветку, вам нужно будет создать и слить это изменение в вашу основную ветку. Как только вы это сделаете, вы увидите, что новое задание пайплайна было запущено для выполнения задания dbt Cloud, которое вы назначили в разделе переменных.

Кроме того, вы увидите задание в истории выполнения dbt Cloud. Его должно быть довольно легко заметить, потому что будет указано, что оно было запущено через API, а в разделе *INFO* будет указана ветка, которую вы использовали для этого руководства.

<Tabs
  defaultValue="github"
  values={[
    { label: 'GitHub', value: 'github', },
    {label: 'GitLab', value: 'gitlab', },
    {label: 'Azure DevOps', value: 'ado', },
    {label: 'Bitbucket', value: 'bitbucket', },
  ]
}>
<TabItem value="github">

<Lightbox src="/img/guides/orchestration/custom-cicd-pipelines/dbt-run-on-merge-github.png" title="Задание dbt run on merge в GitHub" width="80%" />

<Lightbox src="/img/guides/orchestration/custom-cicd-pipelines/dbt-cloud-job-github-triggered.png" title="Задание dbt Cloud, показывающее, что оно было запущено GitHub" width="80%" />

</TabItem>
<TabItem value="gitlab">

<Lightbox src="/img/guides/orchestration/custom-cicd-pipelines/dbt-run-on-merge-gitlab.png" title="Задание dbt run on merge в GitLab" width="80%" />

<Lightbox src="/img/guides/orchestration/custom-cicd-pipelines/dbt-cloud-job-gitlab-triggered.png" title="Задание dbt Cloud, показывающее, что оно было запущено GitLab" width="80%" />

</TabItem>
<TabItem value="ado">

<Lightbox src="/img/guides/orchestration/custom-cicd-pipelines/dbt-run-on-merge-azure.png" width="85%" title="Задание dbt run on merge в ADO"/>

<Lightbox src="/img/guides/orchestration/custom-cicd-pipelines/dbt-cloud-job-azure-triggered.png" width="80" title="Задание, запущенное в dbt Cloud через ADO"/>

</TabItem>
<TabItem value="bitbucket">

<Lightbox src="/img/guides/orchestration/custom-cicd-pipelines/dbt-run-on-merge-bitbucket.png" title="Задание dbt run on merge в Bitbucket" width="80%" />

<Lightbox src="/img/guides/orchestration/custom-cicd-pipelines/dbt-cloud-job-bitbucket-triggered.png" title="Задание dbt Cloud, показывающее, что оно было запущено Bitbucket" width="80%" />

</TabItem>
</Tabs>

## Запуск задания dbt Cloud при запросе на слияние

Если ваш поставщик git не имеет встроенной интеграции с dbt Cloud, но вы все равно хотите воспользоваться преимуществами CI-сборок, вы пришли в нужное место! С небольшими усилиями можно настроить задание, которое будет запускать задание dbt Cloud, когда создается запрос на слияние (PR).

:::tip Запуск при PR

Если ваш поставщик git имеет встроенную интеграцию с dbt Cloud, вы можете воспользоваться инструкциями по настройке [здесь](/docs/deploy/ci-jobs).
Этот раздел предназначен только для тех проектов, которые подключаются к своему репозиторию git с помощью SSH-ключа.

:::

Настройка этого пайплайна будет использовать те же шаги, что и на предыдущей странице. Прежде чем продолжить, выполните шаги 1-5 из [предыдущей страницы](https://docs.getdbt.com/guides/custom-cicd-pipelines?step=2).

### 1. Создайте задание пайплайна, которое запускается при создании PR

<Tabs
  defaultValue="bitbucket"
  values={[
    { label: 'Bitbucket', value: 'bitbucket', },
  ]
}>
<TabItem value="bitbucket">

Для этого задания мы настроим его с помощью файла `bitbucket-pipelines.yml`, как в предыдущем шаге. YAML-файл будет выглядеть довольно похоже на наше предыдущее задание, но мы будем передавать необходимые переменные в Python-скрипт с помощью операторов `export`. Обновите этот раздел, чтобы он соответствовал вашей настройке на основе комментариев в файле.

**Что будет делать этот пайплайн?**  
Настройка ниже будет запускать задание dbt Cloud каждый раз, когда в этом репозитории открывается PR. Он также будет запускать свежую версию пайплайна для каждого коммита, сделанного в ветке PR, до тех пор, пока он не будет слит.
Например: если вы откроете PR, он запустит пайплайн. Если затем вы решите, что нужны дополнительные изменения, и сделаете коммит/пуш в ветку PR, новый пайплайн запустится с обновленным кодом.  

Следующие переменные контролируют это задание:

- `DBT_JOB_BRANCH`: Указывает заданию dbt Cloud запустить код в ветке, которая создала этот PR
- `DBT_JOB_SCHEMA_OVERRIDE`: Указывает заданию dbt Cloud запустить это в пользовательскую целевую схему
  - Формат будет выглядеть так: `DBT_CLOUD_PR_{REPO_KEY}_{PR_NUMBER}`

```yaml
image: python:3.11.1


pipelines:
  # Это задание будет выполняться, когда создаются запросы на слияние в репозитории
  pull-requests:
    '**':
      - step:
          name: 'Запуск задания dbt Cloud PR'
          script:
            # Проверка, чтобы строить только в том случае, если целевая ветка PR - master (или другая ветка). 
            # Закомментируйте или удалите строку ниже, если хотите запускать на всех PR, независимо от целевой ветки.
            - if [ "${BITBUCKET_PR_DESTINATION_BRANCH}" != "main" ]; then printf 'Целевая ветка PR не master, выход.'; exit; fi
            - export DBT_URL="https://cloud.getdbt.com"
            - export DBT_JOB_CAUSE="Bitbucket Pipeline CI Job"
            - export DBT_JOB_BRANCH=$BITBUCKET_BRANCH
            - export DBT_JOB_SCHEMA_OVERRIDE="DBT_CLOUD_PR_"$BITBUCKET_PROJECT_KEY"_"$BITBUCKET_PR_ID
            - export DBT_ACCOUNT_ID=00000 # введите свой идентификатор аккаунта здесь
            - export DBT_PROJECT_ID=00000 # введите свой идентификатор проекта здесь
            - export DBT_PR_JOB_ID=00000 # введите свой идентификатор задания здесь
            - python python/run_and_monitor_dbt_job.py
```

</TabItem>
</Tabs>

### 2. Подтвердите, что пайплайн запускается

Теперь, когда у вас есть новый пайплайн, пришло время запустить его и убедиться, что он работает. Поскольку это срабатывает только при создании PR, вам нужно будет создать новый PR в ветке, содержащей приведенный выше код. Как только вы это сделаете, вы должны увидеть пайплайн, который выглядит так:

<Tabs
  defaultValue="bitbucket"
  values={[
    {label: 'Bitbucket', value: 'bitbucket', },
  ]
}>
<TabItem value="bitbucket">

Пайплайн Bitbucket:
![Задание dbt run on PR в Bitbucket](/img/guides/orchestration/custom-cicd-pipelines/bitbucket-run-on-pr.png)

Задание dbt Cloud:
![Задание dbt Cloud, показывающее, что оно было запущено Bitbucket](/img/guides/orchestration/custom-cicd-pipelines/bitbucket-dbt-cloud-pr.png)

</TabItem>
</Tabs>

### 3. Обработайте дополнительные схемы в вашей базе данных

Как упоминалось выше, когда задание PR запускается, оно создаст новую схему на основе PR. Чтобы избежать перегрузки вашей базы данных схемами PR, рассмотрите возможность добавления задания "очистки" в ваш аккаунт dbt Cloud. Это задание может выполняться по расписанию для очистки любых схем PR, которые не были обновлены/использованы недавно.

Добавьте это как макрос в ваш проект. Он принимает 2 аргумента, которые позволяют вам контролировать, какие схемы будут удалены:

- `age_in_days`: Количество дней с момента последнего изменения схемы, после которого она должна быть удалена (по умолчанию 10 дней)
- `database_to_clean`: Имя базы данных, из которой нужно удалить схемы
  
```sql
{# 
    Этот макрос находит схемы PR старше установленной даты и удаляет их 
    Макрос по умолчанию 10 дней, но может быть настроен с помощью входного аргумента age_in_days
    Пример использования с другой датой:
        dbt run-operation pr_schema_cleanup --args "{'database_to_clean': 'analytics','age_in_days':'15'}"
#}
{% macro pr_schema_cleanup(database_to_clean, age_in_days=10) %}

    {% set find_old_schemas %}
        select 
            'drop schema {{ database_to_clean }}.'||schema_name||';'
        from {{ database_to_clean }}.information_schema.schemata
        where
            catalog_name = '{{ database_to_clean | upper }}'
            and schema_name ilike 'DBT_CLOUD_PR%'
            and last_altered <= (current_date() - interval '{{ age_in_days }} days')
    {% endset %}

    {% if execute %}

        {{ log('Команды удаления схем:' ,True) }}

        {% set schema_drop_list = run_query(find_old_schemas).columns[0].values() %}

        {% for schema_to_drop in schema_drop_list %}
            {% do run_query(schema_to_drop) %}
            {{ log(schema_to_drop ,True) }}
        {% endfor %}

    {% endif %}

{% endmacro %}
```

Этот макрос помещается в задание dbt Cloud, которое выполняется по расписанию. Команда будет выглядеть так (текст ниже для копирования/вставки):
![Задание dbt Cloud, показывающее команду выполнения операции для макроса очистки](/img/guides/orchestration/custom-cicd-pipelines/dbt-macro-cleanup-pr.png)
`dbt run-operation pr_schema_cleanup --args "{ 'database_to_clean': 'development','age_in_days':15}"`

## Учитывайте риск конфликтов при использовании нескольких инструментов оркестрации

Запуск заданий dbt Cloud через пайплайн CI/CD является формой оркестрации заданий. Если вы также запускаете задания с помощью встроенного планировщика dbt Cloud, у вас теперь есть 2 инструмента оркестрации, запускающих задания. Риск в этом заключается в том, что вы можете столкнуться с конфликтами - вы можете представить случай, когда вы запускаете пайплайн при определенных действиях и запускаете запланированные задания в dbt Cloud, вы, вероятно, столкнетесь с конфликтами заданий. Чем больше инструментов у вас есть, тем больше вам нужно убедиться, что все они взаимодействуют друг с другом.

Тем не менее, если **единственная причина, по которой вы хотите использовать пайплайны, это добавление проверки линтинга или запуск при слиянии**, вы можете решить, что плюсы перевешивают минусы, и, таким образом, вы хотите использовать гибридный подход. Просто имейте в виду, что если два процесса попытаются запустить одно и то же задание одновременно, dbt Cloud поставит задания в очередь и выполнит их одно за другим. Это балансировка, но ее можно достичь с усердием, чтобы гарантировать, что вы оркестрируете задания таким образом, чтобы они не конфликтовали.

</div>