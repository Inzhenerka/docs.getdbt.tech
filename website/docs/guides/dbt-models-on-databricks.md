---
title: Оптимизация и устранение неполадок моделей dbt на Databricks
id: optimize-dbt-models-on-databricks
description: "Узнайте больше об оптимизации и устранении неполадок ваших моделей dbt на Databricks"
displayText: Оптимизация и устранение неполадок ваших моделей dbt на Databricks
hoverSnippet: Узнайте, как оптимизировать и устранять неполадки ваших моделей dbt на Databricks.
# time_to_complete: '30 минут' закомментировано до тестирования
icon: 'databricks'
hide_table_of_contents: true
tags: ['Databricks', 'dbt Core','dbt Cloud']
level: 'Средний'
recently_updated: true
---

<div style={{maxWidth: '900px'}}>

## Введение

Основываясь на руководстве [Настройка вашего проекта dbt с Databricks](/guides/set-up-your-databricks-dbt-project), мы хотели бы обсудить оптимизацию производительности. В этом последующем посте мы описываем простые стратегии для оптимизации затрат, производительности и простоты при проектировании конвейеров данных. Мы обобщили эти стратегии в акрониме:

- Компоненты платформы
- Шаблоны и лучшие практики
- Устранение неполадок производительности

## Компоненты платформы

Когда вы начинаете разрабатывать свои проекты dbt, одно из первых решений, которое вам нужно будет принять, — это то, какую инфраструктуру заднего плана использовать для выполнения ваших моделей. Databricks предлагает SQL-склады, универсальные вычисления и вычисления для заданий, каждый из которых оптимизирован для соответствующих рабочих нагрузок. Наша рекомендация — использовать SQL-склады Databricks для всех ваших SQL-рабочих нагрузок. SQL-склады оптимизированы для SQL-рабочих нагрузок по сравнению с другими вариантами вычислений, кроме того, они могут масштабироваться как вертикально для поддержки больших рабочих нагрузок, так и горизонтально для поддержки параллелизма. Также SQL-склады легче управлять и они предоставляют готовые функции, такие как история запросов, чтобы помочь в аудите и оптимизации ваших SQL-рабочих нагрузок. Среди типов SQL-складов, предлагаемых Databricks (Serverless, Pro и Classic), наша стандартная рекомендация — использовать безсерверные склады Databricks. Вы можете изучить функции этих типов складов в разделе [Сравнить функции](https://www.databricks.com/product/pricing/databricks-sql?_gl=1*2rsmlo*_ga*ZmExYzgzZDAtMWU0Ny00N2YyLWFhYzEtM2RhZTQzNTAyZjZi*_ga_PQSEQ3RZQC*MTY3OTYwMDg0Ni4zNTAuMS4xNjc5NjAyMDMzLjUzLjAuMA..&_ga=2.104593536.1471430337.1679342371-fa1c83d0-1e47-47f2-aac1-3dae43502f6b) на странице цен Databricks.

С безсерверными складами вы значительно сокращаете время развертывания, ожидая, пока кластер разогреется, и время масштабирования, когда вашему кластеру необходимо горизонтально масштабироваться. Это уменьшает необходимость держать кластеры в режиме ожидания, так как безсерверные склады быстро запускаются, когда начинается рабочая нагрузка, и затем останавливаются, когда работа завершена. Кроме того, безсерверные склады используют наш движок Photon из коробки для оптимальной производительности как в ELT, так и в рабочих нагрузках обслуживания.

Следующий шаг — решить, какого размера должен быть ваш безсерверный SQL-склад. Это не точная наука, но эти подразделы предоставляют вам несколько быстрых советов, которые приведут к значительным улучшениям в производительности.

### Определение размера ваших SQL-складов

Чтобы выбрать подходящий размер вашего SQL-склада, учитывайте случай использования и рабочую нагрузку, которую вы запускаете, а также соответствующие требования к задержке. Вы можете выбрать размер футболки в зависимости от объема данных и автоматического масштабирования в зависимости от потребностей в параллелизме. Хорошее правило — начать с среднего склада и работать оттуда. Для больших и сложных рабочих нагрузок лучше использовать более крупные склады, и это не обязательно будет означать более высокие затраты. Это связано с тем, что более крупные склады требуют меньше времени для завершения единицы работы. Например, если маленькому складу требуется час для завершения конвейера, то среднему потребуется только полчаса. Эта линейная тенденция продолжается, пока есть достаточно работы для выполнения склада.

### Обеспечение складов по рабочей нагрузке

Еще одна техника, которую стоит реализовать, — это выделение отдельных SQL-складов для построения конвейеров dbt вместо произвольного, интерактивного SQL-анализа. Это связано с тем, что шаблоны проектирования запросов и использование вычислений различаются для этих двух типов рабочих нагрузок. Выбирайте размеры футболок в зависимости от объемов данных и SLA (принцип масштабирования вверх) и выбирайте автоматическое масштабирование в зависимости от требований к параллелизму (принцип масштабирования вширь). Для более крупных развертываний этот подход можно расширить, чтобы сопоставить разные размеры рабочих нагрузок с несколькими "конвейерными" складами, если это необходимо. Со стороны dbt учитывайте [количество потоков, которые у вас есть](/docs/core/connect-data-platform/connection-profiles#understanding-threads), что означает, сколько моделей dbt вы можете запускать параллельно. Чем выше количество потоков, тем больше вычислений вам потребуется.

### Настройка автоматической остановки

Из-за способности безсерверных складов запускаться за считанные секунды, установка конфигурации автоматической остановки на более низкий порог не повлияет на SLA и опыт конечного пользователя. В пользовательском интерфейсе SQL Workspace значение по умолчанию составляет 10 минут, и вы можете установить его на 5 минут для более низкого порога с помощью интерфейса. Если вам нужны более индивидуальные настройки, вы можете установить порог до 1 минуты с помощью [API](https://docs.databricks.com/sql/api/sql-endpoints.html#).

## Шаблоны и лучшие практики

Теперь, когда у нас есть четкое представление о компонентах инфраструктуры, мы можем сосредоточиться на лучших практиках и шаблонах разработки конвейеров. Мы рекомендуем подход с промежуточным/средним/золотым уровнями, который аналогичен архитектуре медальонов бронзового/серебряного/золотого уровней, рекомендованной Databricks. Давайте подробнее разберем каждый этап.

dbt имеет рекомендации о том, как вы можете [структурировать ваш проект dbt](/best-practices/how-we-structure/1-guide-overview), с которыми вы можете ознакомиться.

### Бронзовый / Промежуточный уровень:

Существует несколько различных вариантов материализации бронзовых дельта-таблиц на Databricks. В рекомендованном рабочем процессе dbt вы должны сначала загрузить свои плоские файлы в таблицу, прежде чем использовать dbt для их преобразования. Для этого вы можете использовать инструмент EL для обработки этой загрузки.

Тем не менее, мы понимаем, что это не всегда возможно, поэтому для наборов данных в облачном хранилище мы рекомендуем либо использовать нашу функциональность `COPY INTO`, либо создать промежуточную таблицу. В отношении подхода `COPY INTO` у вас будет несколько различных вариантов. Первый вариант — запустить логику `COPY INTO` в качестве предшествующего действия перед созданием ваших серебряных/промежуточных моделей. Второй вариант — вызвать макрос `COPY INTO` Databricks с помощью `dbt run-operation`, а затем выполнить ваши запуски моделей. Вы можете увидеть пример реализации [макроса COPY INTO](https://github.com/databricks/dbt-databricks/blob/main/docs/databricks-copy-into-macro-aws.md) в документации dbt-databricks.

Основное преимущество использования `COPY INTO` заключается в том, что это инкрементальная операция, и она гарантирует, что данные записываются в формате Delta (когда мы говорим о Delta, мы просто имеем в виду открытые таблицы Parquet с журналом транзакций). Если вы вместо этого решите создать промежуточную таблицу, бронзовая таблица сохранит свою исходную структуру (независимо от того, является ли она CSV, Parquet, JSON и т. д.). Это предотвратит возможность использования преимуществ производительности, надежности и управления, присущих Delta. Кроме того, внешние таблицы Parquet требуют дополнительных ручных действий, таких как выполнение операций восстановления, чтобы гарантировать, что новая метадата разделов учтена. Тем не менее, создание промежуточных таблиц может быть целесообразным вариантом, если вы переходите на Databricks из другой облачной системы складирования, где вы активно использовали эту функциональность.

### Серебряный / Промежуточный уровень

Теперь, когда мы позаботились о нашей бронзовой таблице, мы можем перейти к серебряному уровню.

По причинам затрат и производительности многие клиенты выбирают реализацию инкрементального подхода к конвейерам. Основное преимущество этого подхода заключается в том, что вы обрабатываете гораздо меньше данных, когда вставляете новые записи в серебряный уровень, а не пересоздаете таблицу каждый раз со всеми данными из бронзового уровня. Однако следует отметить, что по умолчанию [dbt рекомендует использовать представления и таблицы](/best-practices/materializations/1-guide-overview) для начала, а затем переходить к инкрементальным, когда вам потребуется больше оптимизации производительности.

dbt имеет [материализацию инкрементальной модели](/reference/resource-configs/spark-configs#the-merge-strategy) для упрощения этой структуры. Как это работает на высоком уровне: Databricks создаст временное представление с моментом данных, а затем объединит этот момент в серебряную таблицу. Вы можете настроить временной диапазон момента, чтобы соответствовать вашему конкретному случаю использования, настроив условие `where` в вашей логике `is_incremental`. Самая простая реализация — объединить данные, используя временную метку, которая позже текущей максимальной временной метки в серебряной таблице, но, безусловно, существуют действительные случаи использования для увеличения временного диапазона исходного момента.

Хотя объединение должно быть довольно производительным из коробки, если у вас особенно строгие SLA, вы можете внедрить некоторые более продвинутые техники настройки в вашу логику. Давайте обсудим несколько примеров более подробно.

### Компакция файлов 

Большинство вычислительных движков работают лучше всего, когда размеры файлов находятся в диапазоне от 32 МБ до 256 МБ. В Databricks мы заботимся об оптимальном размере файлов на уровне системы с помощью наших функций [автооптимизации](https://docs.databricks.com/optimizations/auto-optimize.html). Автооптимизация состоит из двух отдельных функций: автоматической компакции и оптимизированных записей. В SQL-складах Databricks оптимизированные записи включены по умолчанию. Мы рекомендуем вам [подключиться к автоматической компакции](https://docs.databricks.com/optimizations/auto-optimize.html#when-to-opt-in-to-auto-compaction).

### Пропуск данных

На уровне системы Databricks естественным образом [кластеризует данные на основе времени их загрузки](https://www.databricks.com/blog/2022/11/18/introducing-ingestion-time-clustering-dbr-112.html). Поскольку многие запросы включают временные метки в условиях `where`, это естественным образом приведет к большому количеству пропусков файлов для повышения производительности. Тем не менее, если у вас есть другие столбцы с высокой кардинальностью (в основном столбцы с большим количеством уникальных значений, такие как столбцы id), которые часто используются в ключах `join` или условиях `where`, производительность обычно можно дополнительно улучшить, используя Z-упорядочение.

Синтаксис SQL для команды Z-Order: `OPTIMIZE table_name ZORDER BY (col1,col2,col3 и т.д.)`. Одно предостережение, о котором следует помнить, заключается в том, что вы редко захотите Z-упорядочить более чем по трем столбцам. Вы, вероятно, захотите либо запустить Z-упорядочение в конце выполнения вашей модели, либо запустить Z-упорядочение как отдельную запланированную задачу с постоянной периодичностью, будь то ежедневно, еженедельно или ежемесячно.

```sql
config(

materialized='incremental',

zorder="column_A" | ["column_A", "column_B"]

)
```

### Анализ таблицы

Команда `ANALYZE TABLE` гарантирует, что наша система имеет самые актуальные статистические данные для выбора оптимального плана соединения. Вы, вероятно, захотите либо запустить анализ таблицы в качестве постхука после построения вашей модели, либо запустить анализ таблицы как отдельную запланированную задачу dbt с постоянной периодичностью, будь то ежедневно, еженедельно или ежемесячно. Синтаксис SQL для этого:

```sql 
ANALYZE TABLE mytable COMPUTE STATISTICS FOR

COLUMNS col1, col2, col3
```

Важно уточнить, что вы захотите приоритизировать статистику для столбцов, которые часто используются в соединениях.

### Вакуум

Когда вы удаляете запись из таблицы Delta, это мягкое удаление. Это означает, что запись удаляется из журнала транзакций и не включается в последующие запросы, но исходный файл все еще остается в облачном хранилище. Если вы хотите удалить исходные файлы (либо для снижения затрат на хранение, либо для повышения производительности при объединениях), вы можете выполнить команду вакуума. Фактор, о котором вам следует быть очень внимательным, — это восстановление более ранних версий таблицы. Допустим, вы выполняете вакуумирование таблицы, чтобы удалить все неиспользуемые файлы старше 7 дней. Вы не сможете восстановить версии таблицы, которые были созданы более 7 дней назад и зависят от этих удаленных файлов, поэтому используйте с осторожностью. Если/когда вы решите использовать вакуум, вы, вероятно, захотите запустить вакуум с помощью функциональности dbt [on-run-end](/reference/project-configs/on-run-start-on-run-end) после построения вашей модели или запустить вакуум как отдельную запланированную задачу dbt с постоянной периодичностью (будь то ежедневно, еженедельно или ежемесячно) с использованием команды dbt [run-operation](/reference/commands/run-operation) (с оператором вакуума в макросе).

### Золотой / Уровень Мартов

Теперь переходим к самому последнему уровню — золотым мартам, с которыми обычно взаимодействуют бизнес-стейкхолдеры через свои предпочтительные инструменты BI. Условия здесь будут довольно похожи на серебряный уровень, за исключением того, что эти марты, как правило, обрабатывают агрегации. Кроме того, вы, вероятно, захотите быть еще более целенаправленным в Z-упорядочении этих таблиц, поскольку SLA, как правило, ниже для этих таблиц, ориентированных на прямых заинтересованных сторон.

Кроме того, эти таблицы хорошо подходят для определения [метрик](/docs/build/build-metrics-intro), чтобы обеспечить простоту и согласованность по вашим ключевым бизнес-KPI! Используя [MetricFlow](https://github.com/dbt-labs/metricflow), вы можете запрашивать метрики внутри вашего собственного проекта dbt. С предстоящей интеграцией семантического уровня вы также сможете запрашивать метрики в любых интегрированных инструментах-партнерах.

### Фильтрация строк в целевом и/или исходном источнике

Это можно сделать с помощью `incremental_predicates`, как в этом примере: 

```sql
{{

config(

materialized='incremental',

incremental_strategy = 'merge',

unique_key = 'id',

incremental_predicates = [

"dbt_internal_target.create_at >= '2023-01-01'",	"dbt_internal_source.create_at >= '2023-01-01'"],

)

}}
```

## Устранение неполадок производительности

Устранение неполадок производительности относится к процессу выявления и решения проблем, которые влияют на производительность ваших моделей dbt и общих конвейеров данных. Улучшив скорость и производительность вашей платформы Lakehouse, вы сможете быстрее обрабатывать данные, более эффективно обрабатывать большие и сложные запросы и обеспечивать более быстрое время выхода на рынок. Давайте подробнее рассмотрим три эффективные стратегии, которые вы можете реализовать.

### Профиль запроса SQL-склада

Профиль запроса SQL-склада — это эффективный инструмент, который находится внутри рабочей области Databricks SQL. Он используется для устранения неполадок медленно выполняющихся запросов, оптимизации планов выполнения запросов и анализа детализированных метрик, чтобы увидеть, где расходуются вычислительные ресурсы. Профиль запроса включает в себя следующие высокоуровневые области возможностей:

- Подробная информация о трех основных компонентах выполнения запроса, а именно времени, затраченном на задачи, количестве обработанных строк и потреблении памяти.
- Два типа графических представлений. Деревовидный вид для быстрого обнаружения медленных операций и графический вид, который разбивает, как данные преобразуются по задачам.
- Возможность понять ошибки и узкие места производительности в запросах.

Три распространенных примера узких мест производительности, которые могут быть выявлены с помощью профиля запроса:

### Неэффективная обрезка файлов

По умолчанию таблицы Delta в Databricks собирают статистику по _первым 32 столбцам_ в вашей схеме таблицы. При преобразовании данных из бронзового/промежуточного уровня в серебряный/промежуточный уровень рекомендуется изменить порядок ваших столбцов, чтобы учесть эти статистические данные на уровне файлов и улучшить общую производительность. Переместите числовые ключи и предикаты запросов с высокой кардинальностью влево от 32-й порядковой позиции, а строки и сложные типы данных переместите после 32-й порядковой позиции таблицы. Стоит отметить, что хотя вы можете изменить свойство таблицы по умолчанию, чтобы собирать статистику по большему количеству столбцов, это добавит больше накладных расходов при записи файлов. Вы можете изменить это значение по умолчанию, используя [свойство таблицы](https://docs.databricks.com/delta/table-properties.html), `delta.dataSkippingNumIndexedCols`.

### Полные сканирования таблиц

Профиль запроса предоставляет метрики, которые позволяют вам выявить наличие полных сканирований таблиц. Полное сканирование таблиц — это операция запроса, которая включает в себя сканирование всей таблицы для извлечения записей. Это может быть проблемой производительности, особенно для больших таблиц с миллиардами или триллионами строк. Это связано с тем, что сканирование всей таблицы может занять много времени и потребовать много ресурсов, что приводит к высокому использованию памяти и ЦП и более медленным временам отклика. Техники компоновки таблиц, такие как компакция файлов и Z-упорядочение, описанные в предыдущем разделе этой статьи, помогут облегчить эту проблему.

### Взрывные соединения

Концепция _взрывных соединений_ относится к операции `join`, которая производит гораздо больший набор результатов таблицы, чем любая из входных таблиц, что приводит к декартовому произведению. Эта проблема производительности может быть определена путем включения настройки подробного режима в профиле запроса, путем просмотра количества записей, произведенных оператором соединения. Существует несколько шагов, которые вы можете предпринять, чтобы предотвратить взрывные соединения. В качестве первого шага сделайте условия соединения более специфичными, чтобы уменьшить количество строк, которые сопоставляются. Другой шаг — использовать техники предварительной обработки данных, такие как агрегация, фильтрация и выборка данных перед операцией соединения. Эти техники могут уменьшить размер входных таблиц и помочь предотвратить взрывные соединения.

### Лучшие практики материализации  

Помните, что данные хранятся в виде файлов, поэтому единицей работы ввода-вывода является файл, а не строка. Это много работы, если мы имеем дело с ТБ данных. Поэтому мы рекомендуем полагаться на стратегию объединения как рекомендуемую стратегию для большинства инкрементальных моделей.

Databricks стремится постоянно улучшать свою производительность. Например, в Delta и DBSQL мы значительно улучшили производительность операций MERGE в последнее время с помощью [низко-шуфлирующего объединения и Photon](https://www.databricks.com/blog/2022/10/17/faster-merge-performance-low-shuffle-merge-and-photon.html). С множеством будущих реализаций в разработке, таких как векторы удаления для эффективных удалений и обновлений. Вот основные стратегии для ускорения:

1. Читайте только важные разделы, применяя фильтры для сканирования источника и цели с использованием фильтров в *модели* и *incremental_predicates*.
2. Обновляйте только важные строки.
3. Улучшите поиск ключей, определив только *один* материализованный ключ.
4. Обновляйте только важные столбцы.

### API открытия dbt Cloud

Теперь вы, возможно, задаетесь вопросом, как вы можете выявить возможности для улучшения производительности внутри dbt? Каждый раз, когда выполняется задача, dbt Cloud генерирует метаданные о времени, конфигурации и свежести моделей в вашем проекте dbt. [API открытия dbt](/docs/dbt-cloud-apis/discovery-api) — это служба GraphQL, которая поддерживает запросы к этим метаданным, используя [графический исследователь](https://metadata.cloud.getdbt.com/graphiql) или сам конечный пункт. Команды могут передавать эти данные в свое облачное хранилище и анализировать их как любой другой источник данных в платформе бизнес-аналитики. Пользователи dbt Cloud также могут использовать данные из вкладки [Время модели](/docs/deploy/run-visibility#model-timing), чтобы визуально определить модели, которые занимают больше всего времени и могут потребовать рефакторинга.

### API администратора dbt Cloud

С помощью [API администратора dbt Cloud](/docs/dbt-cloud-apis/admin-cloud-api) вы можете извлекать артефакты dbt из вашего запуска dbt Cloud, помещать сгенерированный `manifest.json` в ведро S3, создавать его и моделировать данные с помощью [пакета артефактов dbt](https://hub.getdbt.com/brooklyn-data/dbt_artifacts/latest/). Этот пакет может помочь вам выявить неэффективности в ваших моделях dbt и определить, где есть возможности для улучшения.

### Заключение

Это продолжает содержание в [Настройка вашего проекта dbt с Databricks](/guides/set-up-your-databricks-dbt-project).

Мы приглашаем вас попробовать эти стратегии на нашем примере реализации TPC-H с открытым исходным кодом и поделиться с нами своими мыслями/отзывами, когда вы начнете внедрять эти функции в производство. С нетерпением ждем ваших отзывов в Slack-канале [#db-databricks-and-spark](https://getdbt.slack.com/archives/CNGCW8HKL)!

</div>