---
title: "О микробатчевых инкрементальных моделях"
description: "Узнайте о стратегии 'микробатч' для инкрементальных моделей."
id: "incremental-microbatch"
---

# О микробатчевых инкрементальных моделях <Lifecycle status="beta" />

:::info Микробатч

Новая стратегия `microbatch` доступна в бета-версии для [dbt Cloud "Latest"](/docs/dbt-versions/cloud-release-tracks) и dbt Core v1.9.

Если вы используете пользовательский макрос микробатча, установите [флаг поведения](/reference/global-configs/behavior-changes#custom-microbatch-strategy) в вашем `dbt_project.yml`, чтобы включить пакетное выполнение. Если у вас нет пользовательского макроса микробатча, устанавливать этот флаг не нужно, так как dbt автоматически обработает микробатчинг для любой модели, использующей [стратегию микробатча](#how-microbatch-compares-to-other-incremental-strategies).

Читайте и участвуйте в обсуждении: [dbt-core#10672](https://github.com/dbt-labs/dbt-core/discussions/10672)

Смотрите [Поддерживаемые инкрементальные стратегии по адаптерам](/docs/build/incremental-strategy#supported-incremental-strategies-by-adapter) для получения списка поддерживаемых адаптеров.

:::

## Что такое "микробатч" в dbt?

Инкрементальные модели в dbt — это [материализация](/docs/build/materializations), предназначенная для эффективного обновления таблиц вашего хранилища данных, преобразуя и загружая только _новые или измененные данные_ с момента последнего запуска. Вместо повторной обработки всего набора данных каждый раз, инкрементальные модели обрабатывают меньшее количество строк, а затем добавляют, обновляют или заменяют эти строки в существующей таблице. Это может значительно сократить время и ресурсы, необходимые для ваших преобразований данных.

Микробатч — это инкрементальная стратегия, предназначенная для больших временных рядов данных:
- Она полагается исключительно на временной столбец ([`event_time`](/reference/resource-configs/event-time)) для определения временных диапазонов для фильтрации. Установите столбец `event_time` для вашей модели микробатча и ее прямых родителей (входящих моделей). Обратите внимание, что это отличается от `partition_by`, который группирует строки в разделы.
- Она дополняет, а не заменяет существующие инкрементальные стратегии, сосредотачиваясь на эффективности и простоте пакетной обработки.
- В отличие от традиционных инкрементальных стратегий, микробатч позволяет вам [повторно обрабатывать неудачные пакеты](/docs/build/incremental-microbatch#retry), автоматически определять [параллельное выполнение пакетов](#parallel-batch-execution) и устранять необходимость в реализации сложной условной логики для [обратной загрузки](#backfills).

- Обратите внимание, что микробатч может не быть лучшей стратегией для всех случаев. Рассмотрите другие стратегии для случаев, когда нет надежного столбца `event_time` или если вы хотите больше контроля над инкрементальной логикой. Узнайте больше в [Как `microbatch` сравнивается с другими инкрементальными стратегиями](#how-microbatch-compares-to-other-incremental-strategies).

### Как работает микробатч

Когда dbt запускает модель микробатча — будь то в первый раз, во время инкрементальных запусков или в указанных обратных загрузках — он разделяет обработку на несколько запросов (или "пакетов"), основываясь на `event_time` и `batch_size`, которые вы настраиваете.

Каждый "пакет" соответствует одному ограниченному временно́му периоду (по умолчанию — одному дню данных). В то время как другие инкрементальные стратегии работают только с "старыми" и "новыми" данными, модели микробатча рассматривают каждый пакет как атомарную единицу, которую можно строить или заменять самостоятельно. Каждый пакет независим и <Term id="idempotent" />.

Это мощная абстракция, которая позволяет dbt запускать пакеты [отдельно](#backfills), параллельно и [повторно](#retry) их независимо.

## Пример

Модель `sessions` агрегирует и обогащает данные, поступающие из двух других моделей:
- `page_views` — это большая таблица временных рядов. Она содержит много строк, новые записи почти всегда поступают после существующих, а существующие записи редко обновляются. Она использует столбец `page_view_start` в качестве своего `event_time`.
- `customers` — это относительно небольшая размерная таблица. Атрибуты клиентов обновляются часто и не по временной схеме — то есть, старые клиенты так же вероятно могут изменить значения столбцов, как и новые клиенты. Модель клиентов не настраивает столбец `event_time`.

В результате:

- Каждый пакет `sessions` будет фильтровать `page_views` по эквивалентному временно́му пакету.
- Таблица `customers` не фильтруется, что приводит к полному сканированию для каждого пакета.

:::tip
В дополнение к настройке `event_time` для целевой таблицы, вы также должны указать его для любых входящих моделей, которые вы хотите отфильтровать, даже если у них разные временные столбцы.
:::

<File name="models/staging/page_views.yml">

```yaml
models:
  - name: page_views
    config:
      event_time: page_view_start
```
</File>

Мы запускаем модель `sessions` для 1 октября 2024 года, а затем снова для 2 октября. Это приводит к следующим запросам:

<Tabs>

<TabItem value="Определение модели">

[`event_time`](/reference/resource-configs/event-time) для модели `sessions` установлен на `session_start`, что обозначает начало сессии пользователя на сайте. Эта настройка позволяет dbt объединять несколько просмотров страниц (каждый из которых отслеживается по своим временным меткам `page_view_start`) в одну сессию. Таким образом, `session_start` различает время отдельных просмотров страниц от более широкого временного диапазона всей пользовательской сессии.

<File name="models/sessions.sql">

```sql
{{ config(
    materialized='incremental',
    incremental_strategy='microbatch',
    event_time='session_start',
    begin='2020-01-01',
    batch_size='day'
) }}

with page_views as (

    -- этот ref будет автоматически отфильтрован
    select * from {{ ref('page_views') }}

),

customers as (

    -- этот ref не будет
    select * from {{ ref('customers') }}

),

select
  page_views.id as session_id,
  page_views.page_view_start as session_start,
  customers.*
  from page_views
  left join customers
    on page_views.customer_id = customer.id
```

</File>

</TabItem>

<TabItem value="Скомпилированный (1 окт 2024)">

<File name="target/compiled/sessions.sql">

```sql

with page_views as (

    select * from (
        -- отфильтровано по настроенному event_time
        select * from "analytics"."page_views"
        where page_view_start >= '2024-10-01 00:00:00'  -- 1 окт
        and page_view_start < '2024-10-02 00:00:00'
    )

),

customers as (

    select * from "analytics"."customers"

),

...
```

</File>

</TabItem>

<TabItem value="Скомпилированный (2 окт 2024)">

<File name="target/compiled/sessions.sql">

```sql

with page_views as (

    select * from (
        -- отфильтровано по настроенному event_time
        select * from "analytics"."page_views"
        where page_view_start >= '2024-10-02 00:00:00'  -- 2 окт
        and page_view_start < '2024-10-03 00:00:00'
    )

),

customers as (

    select * from "analytics"."customers"

),

...
```

</File>

</TabItem>

</Tabs>

dbt даст указание платформе данных взять результат каждого пакетного запроса и вставить, обновить или заменить содержимое таблицы `analytics.sessions` для того же дня данных. Для выполнения этой операции dbt использует наиболее эффективный атомарный механизм для "полной пакетной" замены, доступный на каждой платформе данных.

Не имеет значения, содержит ли таблица уже данные за этот день. При одинаковых входных данных результирующая таблица будет одинаковой, независимо от того, сколько раз пакет будет повторно обработан.

<Lightbox src="/img/docs/building-a-dbt-project/microbatch/microbatch_filters.png" title="Каждый пакет сессий фильтрует page_views по соответствующему временно́му пакету, но не фильтрует сессии, выполняя полное сканирование для каждого пакета."/>

## Соответствующие конфигурации

Несколько конфигураций имеют отношение к моделям микробатча, и некоторые из них являются обязательными:

| Конфигурация   |  Описание   | По умолчанию | Тип | Обязательно  |
|----------------|-------------|--------------|------|--------------|
| [`event_time`](/reference/resource-configs/event-time)  | Столбец, указывающий "в какое время произошла строка." Обязателен для вашей модели микробатча и любых прямых родителей, которые должны быть отфильтрованы.   | N/A     |  Столбец  |  Обязательно |
| [`begin`](/reference/resource-configs/begin)      |  "начало времени" для модели микробатча. Это отправная точка для любых начальных или полных обновлений. Например, модель микробатча с дневной гранулярностью, запущенная 1 октября 2024 года с `begin = '2023-10-01'`, обработает 366 пакетов (это високосный год!) плюс пакет для "сегодня."        | N/A     | Дата   | Обязательно |
| [`batch_size`](/reference/resource-configs/batch-size) |  Гранулярность ваших пакетов. Поддерживаемые значения: `hour`, `day`, `month`, и `year`    | N/A     | Строка  | Обязательно |
| [`lookback`](/reference/resource-configs/lookback)   | Обработать X пакетов до последней отметки, чтобы захватить поздно поступившие записи.    | `1`     | Целое число | Необязательно |
| [`concurrent_batches`](/reference/resource-properties/concurrent_batches) | Переопределяет автоматическое определение dbt для одновременного выполнения пакетов (в одно и то же время). Узнайте больше о [настройке параллельных пакетов](/docs/build/incremental-microbatch#configure-concurrent_batches). Установка на <br />* `true` запускает пакеты параллельно (в параллельном режиме). <br />* `false` запускает пакеты последовательно (один за другим).  | `None` | Логическое | Необязательно |

<Lightbox src="/img/docs/building-a-dbt-project/microbatch/event_time.png" title="Столбец event_time настраивает реальное время этой записи"/>

### Обязательные конфигурации для конкретных адаптеров
Некоторые адаптеры требуют дополнительных конфигураций для стратегии микробатча. Это связано с тем, что каждый адаптер реализует стратегию микробатча по-разному.

Следующая таблица перечисляет обязательные конфигурации для конкретных адаптеров, в дополнение к стандартным конфигурациям микробатча:

| Адаптер  | Конфигурация `unique_key` | Конфигурация `partition_by` |
|----------|---------------------------|------------------------------|
| [`dbt-postgres`](/reference/resource-configs/postgres-configs#incremental-materialization-strategies) | ✅ Обязательно | N/A |
| [`dbt-spark`](/reference/resource-configs/spark-configs#incremental-models)    | N/A | ✅ Обязательно |
| [`dbt-bigquery`](/reference/resource-configs/bigquery-configs#merge-behavior-incremental-models) | N/A | ✅ Обязательно |

Например, если вы используете `dbt-postgres`, настройте `unique_key` следующим образом:

<File name="models/sessions.sql">

```sql
{{ config(
    materialized='incremental',
    incremental_strategy='microbatch',
    unique_key='sales_id', ## обязательно для dbt-postgres
    event_time='transaction_date',
    begin='2023-01-01',
    batch_size='day'
) }}

select
    sales_id,
    transaction_date,
    customer_id,
    product_id,
    total_amount
from {{ source('sales', 'transactions') }}

```

В этом примере `unique_key` обязателен, потому что микробатч dbt-postgres использует стратегию `merge`, которая требует `unique_key` для идентификации строк в хранилище данных, которые необходимо объединить. Без `unique_key` dbt не сможет сопоставить строки между входящим пакетом и существующей таблицей.

</File>

### Полное обновление

В качестве лучшей практики мы рекомендуем настраивать `full_refresh: False` для моделей микробатча, чтобы они игнорировали вызовы с флагом `--full-refresh`. Если вам нужно повторно обработать исторические данные, сделайте это с помощью целевой обратной загрузки, которая указывает явные даты начала и окончания.

## Использование

**Вы должны написать запрос вашей модели так, чтобы он обрабатывал (читал и возвращал) ровно один "пакет" данных**. Это упрощающее предположение и мощное:
- Вам не нужно думать о фильтрации `is_incremental`
- Вам не нужно выбирать среди стратегий DML (вставка/объединение/замена)
- Вы можете предварительно просмотреть вашу модель и увидеть точные записи для данного пакета, которые появятся, когда этот пакет будет обработан и записан в таблицу

Когда вы запускаете модель микробатча, dbt оценит, какие пакеты необходимо загрузить, разобьет их на SQL-запросы для каждого пакета и загрузит каждый из них независимо.

dbt автоматически отфильтрует входные данные ( `source` или `ref`), которые определяют `event_time`, на основе конфигураций `lookback` и `batch_size` для этой модели.

Во время стандартных инкрементальных запусков dbt будет обрабатывать пакеты в соответствии с текущей временной меткой и настроенным `lookback`, с одним запросом на пакет.

<Lightbox src="/img/docs/building-a-dbt-project/microbatch/microbatch_lookback.png" title="Настройте lookback для повторной обработки дополнительных пакетов во время стандартных инкрементальных запусков"/>

**Примечание:** Если есть входная модель, которая настраивает `event_time`, но вы *не* хотите, чтобы ссылка на нее фильтровалась, вы можете указать `ref('upstream_model').render()`, чтобы отказаться от автоматической фильтрации. Это обычно не рекомендуется — большинство моделей, которые настраивают `event_time`, довольно большие, и если ссылка не отфильтрована, каждый пакет будет выполнять полное сканирование этой входной таблицы.

## Обратные загрузки

Чтобы исправить ошибочные исходные данные или ретроактивно применить изменение в бизнес-логике, вам может потребоваться повторно обработать большое количество исторических данных.

Обратная загрузка модели микробатча так же проста, как выбор ее для запуска или сборки и указание "начала" и "конца" для `event_time`. Обратите внимание, что `--event-time-start` и `--event-time-end` взаимно необходимы, что означает, что если вы указываете одно, вы должны указать и другое.

Как всегда, dbt будет обрабатывать пакеты между началом и концом как независимые запросы.

```bash
dbt run --event-time-start "2024-09-01" --event-time-end "2024-09-04"
```

<Lightbox src="/img/docs/building-a-dbt-project/microbatch/microbatch_backfill.png" title="Настройте lookback для повторной обработки дополнительных пакетов во время стандартных инкрементальных запусков"/>

## Повторная обработка

Если один или несколько ваших пакетов не удались, вы можете использовать `dbt retry`, чтобы повторно обработать _только_ неудавшиеся пакеты.

![Частичная повторная обработка](https://github.com/user-attachments/assets/f94c4797-dcc7-4875-9623-639f70c97b8f)

## Часовые пояса

На данный момент dbt предполагает, что все предоставленные значения находятся в UTC:

- `event_time`
- `begin`
- `--event-time-start`
- `--event-time-end`

Хотя мы можем рассмотреть возможность добавления поддержки пользовательских часовых поясов в будущем, мы также считаем, что определение этих значений в UTC упрощает жизнь всем.

## Параллельное выполнение пакетов

Стратегия микробатча предлагает преимущество обновления модели меньшими, более управляемыми пакетами. В зависимости от вашего случая использования, настройка ваших моделей микробатча для выполнения параллельно предлагает более быстрое выполнение по сравнению с последовательным выполнением пакетов.

Параллельное выполнение пакетов означает, что несколько пакетов обрабатываются одновременно, а не один за другим (последовательно) для более быстрого выполнения ваших моделей микробатча.

dbt автоматически определяет, может ли пакет выполняться параллельно в большинстве случаев, что означает, что вам не нужно настраивать эту настройку. Однако конфигурация [`concurrent_batches`](/reference/resource-properties/concurrent_batches) доступна в качестве переопределения (не ограничения), позволяя вам указать, должны ли пакеты выполняться параллельно или нет в конкретных случаях.

Например, если у вас есть модель микробатча с 12 пакетами, вы можете выполнить эти пакеты параллельно. В частности, они будут выполняться параллельно, ограниченные количеством [доступных потоков](/docs/running-a-dbt-project/using-threads).

### Предварительные условия

Чтобы включить параллельное выполнение, вы должны:

- Использовать поддерживаемый адаптер:
  - Snowflake
  - Databricks
  - Скоро появятся другие адаптеры!
    - Мы продолжим тестировать и добавлять поддержку параллельного выполнения для адаптеров. Это означает, что некоторые адаптеры могут получить поддержку параллельного выполнения _после_ первоначального выпуска 1.9.
    
- Выполнить [дополнительные условия](#how-parallel-batch-execution-works), описанные в следующем разделе.

### Как работает параллельное выполнение пакетов

Пакет может выполняться параллельно, только если выполнены все эти условия:

| Условие     |  Параллельное выполнение   | Последовательное выполнение|
| ---------------| :------------------: | :----------: |
| **Не** первый пакет |  ✅         | -            |
| **Не** последний пакет  |  ✅         | -            |
| [Адаптер поддерживает](#prerequisites) параллельные пакеты | ✅  | -         |

После проверки условий в предыдущей таблице — и если значение `concurrent_batches` не установлено, dbt интеллектуально автоматически определит, вызывает ли модель [`{{ this }}`](/reference/dbt-jinja-functions/this) функцию Jinja. Если она ссылается на `{{ this }}`, пакеты будут выполняться последовательно, так как `{{ this }}` представляет базу данных текущей модели, и ссылка на одно и то же отношение вызывает конфликт.

В противном случае, если `{{ this }}` не обнаружен (и другие условия выполнены), пакеты будут выполняться параллельно, что можно переопределить, когда вы [установите значение для `concurrent_batches`](/reference/resource-properties/concurrent_batches).

### Параллельное или последовательное выполнение

Выбор между параллельным выполнением пакетов и последовательной обработкой зависит от конкретных требований вашего случая использования.

- Параллельное выполнение пакетов быстрее, но требует логики, независимой от порядка выполнения пакетов. Например, если вы разрабатываете конвейер данных для системы, которая обрабатывает транзакции пользователей пакетами, каждый пакет выполняется параллельно для повышения производительности. Однако логика, используемая для обработки каждой транзакции, не должна зависеть от порядка выполнения или завершения пакетов.
- Последовательная обработка медленнее, но необходима для расчетов, таких как [накопительные метрики](/docs/build/cumulative) в моделях микробатча. Она обрабатывает данные в правильном порядке, позволяя каждому шагу основываться на предыдущем.

### Настройка `concurrent_batches` 

По умолчанию dbt автоматически определяет, могут ли пакеты выполняться параллельно для моделей микробатча, и это работает правильно в большинстве случаев. Однако вы можете переопределить определение dbt, установив конфигурацию [`concurrent_batches`](/reference/resource-properties/concurrent_batches) в вашем `dbt_project.yml` или файле модели `.sql`, чтобы указать параллельное или последовательное выполнение, если вы соответствуете всем [условиям](#prerequisites):

<Tabs>
<TabItem value="yaml" label="dbt_project.yml">

<File name='dbt_project.yml'>

```yaml
models:
  +concurrent_batches: true # значение установлено в true для выполнения пакетов параллельно
```

</File>
</TabItem>

<TabItem value="sql" label="my_model.sql">

<File name='models/my_model.sql'>

```sql
{{
  config(
    materialized='incremental',
    incremental_strategy='microbatch',
    event_time='session_start',
    begin='2020-01-01',
    batch_size='day',
    concurrent_batches=true, # значение установлено в true для выполнения пакетов параллельно
    ...
  )
}}

select ...
```
</File>
</TabItem>
</Tabs>

## Как микробатч сравнивается с другими инкрементальными стратегиями

Поскольку хранилища данных внедряют новые операции для одновременной замены/объединения данных в разделах, мы можем обнаружить, что новая операция для хранилища данных более эффективна, чем то, что адаптер использует для микробатча. В таких случаях мы оставляем за собой право обновить стандартную операцию для микробатча, при условии, что она работает так, как задумано/документировано для моделей, которые соответствуют парадигме микробатча.

Большинство инкрементальных моделей полагаются на конечного пользователя (вас), чтобы явно указать dbt, что "новое" означает в контексте каждой модели, написав фильтр в условном блоке `{% if is_incremental() %}`. Вы несете ответственность за создание этого SQL таким образом, чтобы он запрашивал [`{{ this }}`](/reference/dbt-jinja-functions/this), чтобы проверить, когда последняя запись была загружена, с необязательным окном для поздно поступивших записей.

Другие инкрементальные стратегии будут контролировать _как_ данные добавляются в таблицу — будь то только добавление `insert`, `delete` + `insert`, `merge`, `insert overwrite` и т. д. — но у всех них есть это общее.

В качестве примера:

```sql
{{
    config(
        materialized='incremental',
        incremental_strategy='delete+insert',
        unique_key='date_day'
    )
}}

select * from {{ ref('stg_events') }}

    {% if is_incremental() %}
        -- этот фильтр будет применяться только при инкрементальном запуске
        -- добавьте окно lookback в 3 дня, чтобы учесть поздно поступившие записи
        where date_day >= (select {{ dbt.dateadd("day", -3, "max(date_day)") }} from {{ this }})  
    {% endif %}

```

Для этой инкрементальной модели:

- "Новые" записи — это те, у которых `date_day` больше, чем максимальный `date_day`, который был ранее загружен
- Окно lookback составляет 3 дня
- Когда появляются новые записи для данного `date_day`, существующие данные для `date_day` удаляются, и новые данные вставляются

Давайте возьмем наш тот же пример и вместо этого используем новую инкрементальную стратегию `microbatch`:

<File name="models/staging/stg_events.sql">

```sql
{{
    config(
        materialized='incremental',
        incremental_strategy='microbatch',
        event_time='event_occured_at',
        batch_size='day',
        lookback=3,
        begin='2020-01-01',
        full_refresh=false
    )
}}

select * from {{ ref('stg_events') }} -- этот ref будет автоматически отфильтрован
```

</File>

Где вы также установили `event_time` для прямых родителей модели — в данном случае, `stg_events`:

<File name="models/staging/stg_events.yml">

```yaml
models:
  - name: stg_events
    config:
      event_time: my_time_field
```

</File>

И это все!

Когда вы запускаете модель, каждый пакет шаблонизирует отдельный запрос. Например, если вы запускаете модель 1 октября, dbt создаст отдельные запросы для каждого дня между 28 сентября и 1 октября, включая — всего четыре пакета.

Запрос для `2024-10-01` будет выглядеть так:

<File name="target/compiled/staging/stg_events.sql">

```sql
select * from (
    select * from "analytics"."stg_events"
    where my_time_field >= '2024-10-01 00:00:00'
      and my_time_field < '2024-10-02 00:00:00'
)
```

</File>

В зависимости от вашей платформы данных dbt выберет наиболее эффективный атомарный механизм для вставки, обновления или замены этих четырех пакетов (`2024-09-28`, `2024-09-29`, `2024-09-30` и `2024-10-01`) в существующей таблице.