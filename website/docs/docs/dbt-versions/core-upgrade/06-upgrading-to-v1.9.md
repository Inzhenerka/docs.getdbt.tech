---
title: "Обновление до версии v1.9"
id: upgrading-to-v1.9
description: Новые функции и изменения в dbt Core v1.9
displayed_sidebar: "docs"
---

## Ресурсы

- [Журнал изменений dbt Core 1.9](https://github.com/dbt-labs/dbt-core/blob/1.9.latest/CHANGELOG.md)
- [Руководство по установке dbt Core CLI](/docs/core/installation-overview)
- [Руководство по обновлению в облаке](/docs/dbt-versions/upgrade-dbt-version-in-cloud#release-tracks)

## Что нужно знать перед обновлением

dbt Labs стремится обеспечивать обратную совместимость для всех версий 1.x. Любые изменения в поведении будут сопровождаться [флагом изменения поведения](/reference/global-configs/behavior-changes#behavior-change-flags), чтобы предоставить окно для миграции существующих проектов. Если вы столкнетесь с ошибкой при обновлении, пожалуйста, сообщите нам, [открыв проблему](https://github.com/dbt-labs/dbt-core/issues/new).

Начиная с 2024 года, dbt Cloud предоставляет функциональность из новых версий dbt Core через [треки выпусков](/docs/dbt-versions/cloud-release-tracks) с автоматическими обновлениями. Если вы выбрали трек "Latest" в dbt Cloud, у вас уже есть доступ ко всем функциям, исправлениям и другим возможностям, которые включены в dbt Core v1.9! Если вы выбрали трек "Compatible", вы получите доступ в следующем ежемесячном выпуске "Compatible" после финального выпуска dbt Core v1.9.

Для пользователей dbt Core, начиная с версии v1.8, мы рекомендуем явно устанавливать как `dbt-core`, так и `dbt-<youradapter>`. Это может стать обязательным в будущей версии dbt. Например:

```sql
python3 -m pip install dbt-core dbt-snowflake
```

## Новые и измененные функции и функциональность

Новые функции и функциональность в dbt v1.9.

### `incremental_strategy` с микропакетами

:::info

Если вы используете пользовательский макрос микропакетов, установите флаг поведения [`require_batched_execution_for_custom_microbatch_strategy`](/reference/global-configs/behavior-changes#custom-microbatch-strategy) в вашем `dbt_project.yml`, чтобы включить пакетное выполнение. Если у вас нет пользовательского макроса микропакетов, вам не нужно устанавливать этот флаг, так как dbt автоматически обработает микропакетирование для любой модели, использующей стратегию микропакетов.
:::

Инкрементальные модели всегда были *оптимизацией производительности* — для наборов данных, которые слишком велики, чтобы их можно было удалять и воссоздавать с нуля каждый раз, когда вы выполняете `dbt run`. Узнайте больше об [инкрементальных моделях](/docs/build/incremental-models-overview).

Исторически управление инкрементальными моделями включало несколько ручных шагов и обязанностей, включая:

- Добавление фрагмента кода dbt (в блоке `is_incremental()`), который использует уже существующую таблицу (`this`) в качестве грубой закладки, чтобы обрабатывать только новые данные.
- Выбор одной из стратегий для объединения старых и новых данных (`append`, `delete+insert` или `merge`).
- Если что-то идет не так или ваша схема изменяется, вы всегда можете выполнить "полное обновление", запустив тот же простой запрос, который перестраивает всю таблицу с нуля.

Хотя это работает для многих случаев использования, у этого подхода есть явное ограничение: *Некоторые наборы данных просто слишком велики, чтобы поместиться в один запрос.*

Начиная с Core 1.9, вы можете использовать новую [стратегию микропакетов](/docs/build/incremental-microbatch#what-is-microbatch-in-dbt) для оптимизации ваших самых больших наборов данных — **обрабатывайте ваши данные событий в дискретные периоды с их собственными SQL-запросами, а не все сразу.** Преимущества включают:

- Упрощенный дизайн запросов: Напишите запрос вашей модели для одного пакета данных. dbt будет использовать ваши конфигурации `event_time`, `lookback` и `batch_size`, чтобы автоматически генерировать необходимые фильтры для вас, упрощая процесс и уменьшая необходимость управлять этими деталями.
- Независимая обработка пакетов: dbt автоматически разбивает данные на более мелкие пакеты на основе указанного `batch_size` и обрабатывает каждый пакет независимо, улучшая эффективность и снижая риск тайм-аутов запросов. Если некоторые из ваших пакетов не удается обработать, вы можете использовать `dbt retry`, чтобы загрузить только неудавшиеся пакеты.
- Целевая повторная обработка: Чтобы загрузить *конкретный* пакет или пакеты, вы можете использовать аргументы CLI `--event-time-start` и `--event-time-end`.
- [Автоматическое параллельное выполнение пакетов](/docs/build/incremental-microbatch#parallel-batch-execution): Обрабатывайте несколько пакетов одновременно, вместо одного за другим (последовательно) для более быстрой обработки ваших моделей микропакетов. dbt интеллектуально автоматически определяет, могут ли ваши пакеты выполняться параллельно, при этом позволяя вам вручную переопределить параллельное выполнение с помощью конфигурации [`concurrent_batches`](/reference/resource-properties/concurrent_batches).

В настоящее время микропакеты поддерживаются на следующих адаптерах, и в будущем их станет больше:
 * postgres
 * redshift
 * snowflake
 * bigquery
 * spark
 * databricks

### Улучшения снимков

Начиная с dbt Core 1.9, мы упростили конфигурацию снимков и добавили несколько новых конфигураций, чтобы сделать **снимки dbt проще в настройке, запуске и кастомизации.** Эти улучшения включают:

- Новая спецификация снимков: Снимки теперь можно настраивать в YAML-файле, что обеспечивает более чистую и согласованную настройку.
- Новая конфигурация `snapshot_meta_column_names`: Позволяет вам кастомизировать имена мета-полей (например, `dbt_valid_from`, `dbt_valid_to` и т.д.), которые dbt автоматически добавляет к снимкам. Это увеличивает гибкость для адаптации метаданных к вашим нуждам.
- `target_schema` теперь является необязательным для снимков: Если не указано, снимки будут использовать схему, определенную для текущей среды.
- Поддержка стандартных конфигураций `schema` и `database`: Снимки теперь будут согласованы с другими типами ресурсов dbt. Вы можете указать, где должны храниться снимки, зависящие от среды.
- Предупреждение о неправильном типе данных `updated_at`: Чтобы обеспечить целостность данных, вы увидите предупреждение, если поле `updated_at`, указанное в конфигурации снимка, не является правильным типом данных или временной меткой.
- Установите пользовательский текущий индикатор для значения `dbt_valid_to`: Используйте конфигурацию [`dbt_valid_to_current`](/reference/resource-configs/dbt_valid_to_current), чтобы установить пользовательский индикатор для значения `dbt_valid_to` в текущих записях снимка (например, будущая дата). По умолчанию это значение `NULL`. Когда настроено, dbt будет использовать указанное значение вместо `NULL` для `dbt_valid_to` для текущих записей в таблице снимков.
- Используйте конфигурацию [`hard_deletes`](/reference/resource-configs/hard-deletes), чтобы получить больший контроль над тем, как обрабатывать удаленные строки из источника. Поддерживаемые методы: `ignore` (по умолчанию), `invalidate` (заменяет устаревший `invalidate_hard_deletes=true`) и `new_record`. Установка `hard_deletes='new_record'` позволяет отслеживать жесткие удаления, добавляя новую запись, когда строка становится "удаленной" в источнике.

Узнайте больше о [мета-полях снимков](/docs/build/snapshots#snapshot-meta-fields).

Чтобы узнать, как безопасно мигрировать существующие снимки, обратитесь к [миграции конфигурации снимков](/reference/snapshot-configs#snapshot-configuration-migration) для получения дополнительной информации.

### Улучшения `state:modified`

Мы внесли улучшения в поведение `state:modified`, чтобы помочь снизить риск ложных срабатываний и пропусков. Узнайте больше о [флаге поведения `state:modified`](#managing-changes-to-legacy-behaviors), который разблокирует это улучшение:

- Добавлены улучшения, зависящие от среды, для сред, где логика намеренно отличается (например, материализация в виде таблицы в `prod`, но в виде `view` в dev).

### Управление изменениями в устаревших поведениях

dbt Core v1.9 имеет несколько новых флагов для [управления изменениями в устаревших поведениях](/reference/global-configs/behavior-changes). Вы можете включить недавно введенные изменения (отключены по умолчанию) или отключить зрелые изменения (включены по умолчанию), установив значения `True` / `False` соответственно для `flags` в `dbt_project.yml`.

Вы можете узнать больше о каждом из этих изменений поведения по следующим ссылкам:

- (Введено, отключено по умолчанию) [`state_modified_compare_more_unrendered_values`](/reference/global-configs/behavior-changes#behavior-change-flags). Установите в `True`, чтобы начать сохранять `unrendered_database` и `unrendered_schema` конфигурации во время парсинга источника и выполнять сравнение на неотрендеренных значениях во время проверок `state:modified`, чтобы уменьшить ложные срабатывания из-за логики, зависящей от среды, при выборе `state:modified`.
- (Введено, отключено по умолчанию) [`skip_nodes_if_on_run_start_fails` проектный флаг конфигурации](/reference/global-configs/behavior-changes#behavior-change-flags). Если флаг установлен и **любой** `on-run-start` хук не удается, пометьте все выбранные узлы как пропущенные.
    - `on-run-start/end` хуки **всегда** выполняются, независимо от того, прошли они или не прошли в прошлый раз.
- (Введено, отключено по умолчанию) [[Redshift] `restrict_direct_pg_catalog_access`](/reference/global-configs/behavior-changes#redshift-restrict_direct_pg_catalog_access). Если флаг установлен, адаптер будет использовать API Redshift (через клиент Python), если он доступен, или запрашивать таблицы `information_schema` Redshift вместо использования таблиц `pg_`.
- (Введено, отключено по умолчанию) [`require_nested_cumulative_type_params`](/reference/global-configs/behavior-changes#cumulative-metrics). Если флаг установлен в `True`, пользователи получат ошибку вместо предупреждения, если они неправильно форматируют кумулятивные метрики, используя новое вложение [`cumulative_type_params`](/docs/build/cumulative#parameters).
- (Введено, отключено по умолчанию) [`require_batched_execution_for_custom_microbatch_strategy`](/reference/global-configs/behavior-changes#custom-microbatch-strategy). Установите в `True`, если вы используете пользовательский макрос микропакетов для включения пакетного выполнения. Если у вас нет пользовательского макроса микропакетов, вам не нужно устанавливать этот флаг, так как dbt автоматически обработает микропакетирование для любой модели, использующей стратегию микропакетов.

## Специфические для адаптеров функции и функциональность

### Redshift

- Поддержка аутентификации через IAM Role

### Snowflake

- Поддержка формата таблиц Iceberg будет доступна на трех встроенных материализациях: table, incremental, dynamic tables.

### Bigquery

- Возможность отмены выполняющихся запросов при прерывании клавиатурой
- Автоматическое удаление промежуточных таблиц, созданных инкрементальными моделями, для экономии ресурсов

### Spark

- Поддержка переопределения строки подключения драйвера ODBC, что теперь позволяет вам предоставлять пользовательские подключения

## Быстрые изменения

Мы также внесли некоторые улучшения в качество жизни в Core 1.9, позволяя вам:

- Поддерживать качество данных, теперь когда dbt возвращает ошибку (версионные модели) или предупреждение (неверсионные модели), когда кто-то [удаляет контрактную модель, удаляя, переименовывая или отключая](/docs/collaborate/govern/model-contracts#how-are-breaking-changes-handled) ее.
- Документировать [тесты данных](/reference/resource-properties/description).
- Использовать `ref` и `source` в [ограничениях внешнего ключа](/reference/resource-properties/constraints).
- Использовать `dbt test` с флагом `--resource-type` / `--exclude-resource-type`, что позволяет включать или исключать тесты данных (`test`) или модульные тесты (`unit_test`).