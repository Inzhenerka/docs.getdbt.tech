---
title: "Обновление до v1.9"
id: upgrading-to-v1.9
description: Новые функции и изменения в dbt Core v1.9
displayed_sidebar: "docs"
---

## Ресурсы

- [Changelog dbt Core 1.9](https://github.com/dbt-labs/dbt-core/blob/1.9.latest/CHANGELOG.md)
- [Руководство по установке dbt Core CLI](/docs/core/installation-overview)
- [Руководство по обновлению в облаке](/docs/dbt-versions/upgrade-dbt-version-in-cloud#release-tracks)

## Что нужно знать перед обновлением

dbt Labs стремится обеспечить обратную совместимость для всех версий 1.x. Любые изменения в поведении будут сопровождаться [флагом изменения поведения](/reference/global-configs/behavior-changes#behavior-change-flags), чтобы предоставить окно миграции для существующих проектов. Если вы столкнетесь с ошибкой после обновления, пожалуйста, дайте нам знать, [открыв проблему](https://github.com/dbt-labs/dbt-core/issues/new).

Начиная с 2024 года, dbt Cloud предоставляет функциональность новых версий dbt Core через [релизные треки](/docs/dbt-versions/cloud-release-tracks) с автоматическими обновлениями. Если вы выбрали "Последний" релизный трек в dbt Cloud, вы уже имеете доступ ко всем функциям, исправлениям и другой функциональности, включенной в dbt Core v1.9! Если вы выбрали "Совместимый" релизный трек, вы получите доступ в следующем ежемесячном "Совместимом" релизе после окончательного релиза dbt Core v1.9.

Для пользователей dbt Core с версии v1.8 мы рекомендуем явно устанавливать как `dbt-core`, так и `dbt-<вашадаптер>`. Это может стать обязательным для будущей версии dbt. Например:

```sql
python3 -m pip install dbt-core dbt-snowflake
```

## Новые и измененные функции и функциональность

Функции и функциональность, новые в dbt v1.9.

### Стратегия `incremental_strategy` для микропакетов

:::info

Если вы используете пользовательский макрос микропакетов, установите флаг поведения [`require_batched_execution_for_custom_microbatch_strategy`](/reference/global-configs/behavior-changes#custom-microbatch-strategy) в вашем `dbt_project.yml`, чтобы включить пакетное выполнение. Если у вас нет пользовательского макроса микропакетов, вам не нужно устанавливать этот флаг, так как dbt будет автоматически обрабатывать микропакетирование для любой модели, использующей стратегию микропакетов.
:::

Инкрементальные модели являются и всегда были *оптимизацией производительности* — для наборов данных, которые слишком велики, чтобы их можно было удалить и воссоздать с нуля каждый раз, когда вы выполняете `dbt run`. Узнайте больше о [инкрементальных моделях](/docs/build/incremental-models-overview).

Исторически управление инкрементальными моделями включало несколько ручных шагов и обязанностей, включая:

- Добавление фрагмента кода dbt (в блоке `is_incremental()`), который использует уже существующую таблицу (`this`) в качестве грубого закладки, чтобы обрабатывались только новые данные.
- Выбор одной из стратегий для объединения старых и новых данных (`append`, `delete+insert` или `merge`).
- Если что-то пойдет не так или ваша схема изменится, вы всегда можете выполнить "полное обновление", запустив тот же простой запрос, который воссоздает всю таблицу с нуля.

Хотя это работает для многих случаев, у этого подхода есть явное ограничение: *Некоторые наборы данных просто слишком велики, чтобы уместиться в один запрос.*

Начиная с Core 1.9, вы можете использовать новую [стратегию микропакетов](/docs/build/incremental-microbatch#what-is-microbatch-in-dbt) для оптимизации ваших самых больших наборов данных — **обрабатывайте ваши данные событий в дискретные периоды с их собственными SQL-запросами, а не все сразу.** Преимущества включают:

- Упрощенный дизайн запроса: Напишите запрос вашей модели для одного пакета данных. dbt будет использовать ваши конфигурации `event_time`, `lookback` и `batch_size`, чтобы автоматически сгенерировать необходимые фильтры для вас, упрощая процесс и уменьшая необходимость управлять этими деталями.
- Независимая обработка пакетов: dbt автоматически разбивает данные для загрузки на более мелкие пакеты на основе указанного `batch_size` и обрабатывает каждый пакет независимо, улучшая эффективность и снижая риск тайм-аутов запросов. Если некоторые из ваших пакетов не удастся загрузить, вы можете использовать `dbt retry`, чтобы загрузить только неудавшиеся пакеты.
- Целевая переработка: Чтобы загрузить *определенный* пакет или пакеты, вы можете использовать аргументы CLI `--event-time-start` и `--event-time-end`.
- [Автоматическое параллельное выполнение пакетов](/docs/build/incremental-microbatch#parallel-batch-execution): Обрабатывайте несколько пакетов одновременно, а не один за другим (последовательно) для более быстрой обработки ваших моделей микропакетов. dbt интеллектуально автоматически определяет, могут ли ваши пакеты выполняться параллельно, а также позволяет вам вручную переопределить параллельное выполнение с помощью конфигурации [`concurrent_batches`](/reference/resource-properties/concurrent_batches).

В настоящее время поддержка микропакетов доступна для следующих адаптеров, и в будущем будет добавлена поддержка для других:
 * postgres
 * redshift
 * snowflake
 * bigquery
 * spark
 * databricks

### Улучшения снимков

Начиная с dbt Core 1.9, мы упростили конфигурацию снимков и добавили несколько новых конфигураций, чтобы сделать dbt **снимки проще в настройке, запуске и настройке.** Эти улучшения включают:

- Новая спецификация снимка: Снимки теперь можно настраивать в YAML-файле, что обеспечивает более чистую и последовательную настройку.
- Новая конфигурация `snapshot_meta_column_names`: Позволяет вам настраивать названия метаполей (например, `dbt_valid_from`, `dbt_valid_to` и т.д.), которые dbt автоматически добавляет к снимкам. Это увеличивает гибкость в настройке метаданных под ваши нужды.
- `target_schema` теперь является необязательным для снимков: При его отсутствии снимки будут использовать схему, определенную для текущей среды.
- Поддержка стандартных конфигураций `schema` и `database`: Снимки теперь будут согласованы с другими типами ресурсов dbt. Вы можете указать, где должны храниться снимки, учитывающие среду.
- Предупреждение о неправильном типе данных `updated_at`: Чтобы обеспечить целостность данных, вы увидите предупреждение, если поле `updated_at`, указанное в конфигурации снимка, не имеет правильного типа данных или временной метки.
- Установите пользовательский индикатор текущего значения для `dbt_valid_to`: Используйте конфигурацию [`dbt_valid_to_current`](/reference/resource-configs/dbt_valid_to_current), чтобы установить пользовательский индикатор для значения `dbt_valid_to` в текущих записях снимка (например, будущая дата). По умолчанию это значение `NULL`. При настройке dbt будет использовать указанное значение вместо `NULL` для `dbt_valid_to` для текущих записей в таблице снимков.
- Используйте конфигурацию [`hard_deletes`](/reference/resource-configs/hard-deletes), чтобы получить больше контроля над тем, как обрабатывать удаленные строки из источника. Поддерживаемые методы: `ignore` (по умолчанию), `invalidate` (заменяет устаревший `invalidate_hard_deletes=true`) и `new_record`. Установка `hard_deletes='new_record'` позволяет вам отслеживать жесткие удаления, добавляя новую запись, когда строка становится "удаленной" в источнике.

Узнайте больше о [метаполях снимков](/docs/build/snapshots#snapshot-meta-fields).

Чтобы узнать, как безопасно мигрировать существующие снимки, обратитесь к [миграции конфигурации снимков](/reference/snapshot-configs#snapshot-configuration-migration) для получения дополнительной информации.

### Улучшения `state:modified`

Мы внесли улучшения в поведение `state:modified`, чтобы помочь снизить риск ложных срабатываний и пропусков. Узнайте больше о [флаге поведения `state:modified`](#managing-changes-to-legacy-behaviors), который открывает это улучшение:

- Добавлены улучшения, учитывающие среду, для сред, где логика намеренно отличается (например, материализация как таблица в `prod`, но как `view` в dev).

### Управление изменениями в устаревшем поведении

dbt Core v1.9 имеет несколько новых флагов для [управления изменениями в устаревшем поведении](/reference/global-configs/behavior-changes). Вы можете включить недавно введенные изменения (по умолчанию отключены) или отключить устоявшиеся изменения (по умолчанию включены), установив значения `True` / `False` соответственно для `flags` в `dbt_project.yml`.

Вы можете узнать больше о каждом из этих изменений поведения по следующим ссылкам:

- (Введен, отключен по умолчанию) [`state_modified_compare_more_unrendered_values`](/reference/global-configs/behavior-changes#behavior-change-flags). Установите значение `True`, чтобы начать сохранять конфигурации `unrendered_database` и `unrendered_schema` во время парсинга источника и проводить сравнение по неотрендеренным значениям во время проверок `state:modified`, чтобы уменьшить ложные срабатывания из-за логики, учитывающей среду, при выборе `state:modified`.
- (Введен, отключен по умолчанию) [`skip_nodes_if_on_run_start_fails` проектный флаг конфигурации](/reference/global-configs/behavior-changes#behavior-change-flags). Если флаг установлен и **любой** хук `on-run-start` завершился неудачно, все выбранные узлы будут помечены как пропущенные.
    - Хуки `on-run-start/end` **всегда** выполняются, независимо от того, прошли они или провалились в прошлый раз.
- (Введен, отключен по умолчанию) [[Redshift] `restrict_direct_pg_catalog_access`](/reference/global-configs/behavior-changes#redshift-restrict_direct_pg_catalog_access). Если флаг установлен, адаптер будет использовать API Redshift (через Python-клиент), если он доступен, или запрашивать таблицы `information_schema` Redshift вместо использования таблиц `pg_`.
- (Введен, отключен по умолчанию) [`require_nested_cumulative_type_params`](/reference/global-configs/behavior-changes#cumulative-metrics). Если флаг установлен в `True`, пользователи получат ошибку вместо предупреждения, если они неправильно форматируют кумулятивные метрики, используя новые параметры [`cumulative_type_params`](/docs/build/cumulative#parameters).
- (Введен, отключен по умолчанию) [`require_batched_execution_for_custom_microbatch_strategy`](/reference/global-configs/behavior-changes#custom-microbatch-strategy). Установите значение `True`, если вы используете пользовательский макрос микропакетов, чтобы включить пакетное выполнение. Если у вас нет пользовательского макроса микропакетов, вам не нужно устанавливать этот флаг, так как dbt будет автоматически обрабатывать микропакетирование для любой модели, использующей стратегию микропакетов.

## Специфические функции и функциональность адаптеров

### Redshift

- Поддержка аутентификации IAM Role

### Snowflake

- Поддержка формата таблиц Iceberg будет доступна для трех стандартных материализаций: таблица, инкрементальная, динамические таблицы.

### Bigquery

- Возможность отмены выполняющихся запросов при прерывании с клавиатуры
- Автоудаление промежуточных таблиц, созданных инкрементальными моделями, для экономии ресурсов

### Spark

- Поддержка переопределения строки подключения ODBC-драйвера, что теперь позволяет предоставлять пользовательские подключения

## Быстрые улучшения

Мы также внесли некоторые улучшения качества жизни в Core 1.9, позволяя вам:

- Поддерживать качество данных, теперь dbt возвращает ошибку (версионированные модели) или предупреждение (неверсионированные модели), когда кто-то [удаляет контрактованную модель, удаляя, переименовывая или отключая](/docs/collaborate/govern/model-contracts#how-are-breaking-changes-handled) ее.
- Документировать [тесты данных](/reference/resource-properties/description).
- Использовать `ref` и `source` в [ограничениях внешних ключей](/reference/resource-properties/constraints).
- Использовать `dbt test` с флагом `--resource-type` / `--exclude-resource-type`, что позволяет включать или исключать тесты данных (`test`) или модульные тесты (`unit_test`).