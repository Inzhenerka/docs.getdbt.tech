---
title: "Обновление до версии v1.1"
description: Новые функции и изменения в dbt Core v1.1
id: "upgrading-to-v1.1"
displayed_sidebar: "docs"
---

### Ресурсы

- [Журнал изменений](https://github.com/dbt-labs/dbt-core/blob/1.1.latest/CHANGELOG.md)
- [Руководство по установке CLI <Constant name="core" />](/docs/core/installation-overview)
- [Руководство по обновлению Cloud](/docs/dbt-versions/upgrade-dbt-version-in-cloud)

## Что нужно знать перед обновлением

Нет критических изменений для кода в проектах и пакетах dbt. Мы стремимся обеспечивать обратную совместимость для всех версий 1.x. Если вы столкнетесь с ошибкой при обновлении, пожалуйста, сообщите нам, [создав задачу](https://github.com/dbt-labs/dbt-core/issues/new).

### Для разработчиков адаптеров

Мы переработали набор тестов для функциональности адаптеров. Для получения подробной информации о новом наборе тестов обратитесь к шагу "Тестирование вашего адаптера" в руководстве [Создание, тестирование, документирование и продвижение адаптеров](/guides/adapter-creation).

Абстрактные методы `get_response` и `execute` теперь возвращают только `connection.AdapterReponse` в подсказках типов. Ранее они могли возвращать строку. Мы рекомендуем обновить ваши методы, чтобы они возвращали объект класса `AdapterResponse`, или реализовать подкласс, специфичный для вашего адаптера. Это также дает вам возможность добавить поля, специфичные для выполнения запросов вашего адаптера, такие как `rows_affected` или `bytes_processed`.

### Для пользователей артефактов dbt (метаданные)

Версия схемы манифеста будет обновлена до v5. Единственное изменение касается значения по умолчанию для `config` для разобранных узлов.

Для пользователей [функциональности на основе состояния](/reference/node-selection/syntax#about-node-selection), такой как селектор `state:modified`, помните, что:

> Артефакты `--state` должны быть версий схем, совместимых с текущей версией dbt.

Если у вас есть две задачи, где одна сравнивает или откладывает артефакты, созданные другой, вам нужно будет обновить обе одновременно. Если есть несоответствие, dbt предупредит вас следующим сообщением об ошибке:

```
Ожидалась версия схемы "https://schemas.getdbt.com/dbt/manifest/v5.json" в <state-path>/manifest.json, но найдена "https://schemas.getdbt.com/dbt/manifest/v4.json". Вы используете другую версию dbt?
```

## Новая и измененная документация

[**Инкрементальные модели**](/docs/build/incremental-models) теперь могут принимать список из нескольких столбцов в качестве `unique_key` для моделей, которым требуется комбинация столбцов для уникальной идентификации каждой строки. Это поддерживается наиболее распространенными <Term id="data-warehouse">хранилищами данных</Term> для инкрементальных стратегий, использующих конфигурацию `unique_key` (`merge` и `delete+insert`).

[**Генерические тесты**](/reference/resource-properties/data-tests) могут определять пользовательские имена. Это полезно для "украшения" синтетического имени, которое dbt применяет автоматически. Это необходимо для устранения неоднозначности в случае, когда один и тот же генерический тест определяется несколько раз с разными конфигурациями.

[**Источники**](/reference/source-properties) могут определять конфигурацию в строке с другими свойствами `.yml`, как и другие типы ресурсов. Единственная поддерживаемая конфигурация — `enabled`; вы можете использовать это для динамического включения/отключения источников на основе переменных окружения или пакета.

### Продвинутая и экспериментальная функциональность

**Fresh Rebuilds.** В городе появился новый _экспериментальный_ метод выбора: [`source_status:fresher`](/reference/node-selection/methods#source_status). Подобно методам `state:` и `result`, его цель — использовать метаданные dbt, чтобы запускать ваш DAG более эффективно. Если у dbt есть доступ к предыдущим и текущим результатам `dbt source freshness` (артефакт `sources.json`), dbt может сравнить их, чтобы определить, какие источники загрузили новые данные, и выбрать только ресурсы, находящиеся ниже по DAG от «более свежих» источников. Подробнее читайте в разделах [Understanding State](/reference/node-selection/syntax#about-node-selection) и [CI/CD in <Constant name="cloud" />](/docs/deploy/continuous-integration).

[**Функции dbt-Jinja**](/reference/dbt-jinja-functions) получили новую стартовую страницу и двух новых участников:
- [`print`](/reference/dbt-jinja-functions/print) предоставляет функцию Python `print()`. Она может использоваться как альтернатива `log()`, и вместе с конфигурацией `QUIET`, для продвинутых рабочих процессов, управляемых макросами.
- [`selected_resources`](/reference/dbt-jinja-functions/selected_resources) предоставляет, во время выполнения, список узлов DAG, выбранных текущей задачей.

[**Глобальные конфигурации**](/reference/global-configs/about-global-configs) включают некоторые новые дополнения:

- `QUIET` и `NO_PRINT`, для управления тем, какие сообщения журнала dbt выводит в терминал. Для использования в продвинутых рабочих процессах, управляемых макросами, таких как [codegen](https://hub.getdbt.com/dbt-labs/codegen/latest/).
- `CACHE_SELECTED_ONLY` — это _экспериментальная_ конфигурация, которая может значительно ускорить подготовку dbt к запуску, в случаях, когда вы запускаете только несколько моделей из большого проекта, управляющего многими схемами.

### Для пользователей конкретных адаптеров

**dbt-bigquery** добавил поддержку <Term id="grain">более детальной</Term> конфигурации времени ожидания запроса и повторной попытки при определении вашего [профиля подключения](/docs/core/connect-data-platform/bigquery-setup).

**dbt-spark** добавил поддержку метода подключения [`session`](/docs/core/connect-data-platform/spark-setup#session), для использования с сессией pySpark, чтобы поддерживать быструю итерацию при разработке продвинутой или экспериментальной функциональности. Этот метод подключения не рекомендуется для новых пользователей и не поддерживается в dbt Cloud.

**dbt-spark** получил поддержку [метода подключения `session`](/docs/core/connect-data-platform/spark-setup#session), предназначенного для использования с сессией pySpark. Это позволяет ускорить итерации при разработке продвинутой или экспериментальной функциональности. Данный метод подключения не рекомендуется для новых пользователей и не поддерживается в <Constant name="cloud" />.

### Зависимости

[Совместимость с Python](/faqs/Core/install-python-compatibility): <Constant name="core" /> официально поддерживает Python 3.10
